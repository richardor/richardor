<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>后台服务开发</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.servercoder.com/"/>
  <updated>2019-04-24T14:56:22.062Z</updated>
  <id>http://www.servercoder.com/</id>
  
  <author>
    <name>码龙</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>一文读懂gpu计算的前世今生</title>
    <link href="http://www.servercoder.com/2019/04/24/gpu-started/"/>
    <id>http://www.servercoder.com/2019/04/24/gpu-started/</id>
    <published>2019-04-24T14:55:53.081Z</published>
    <updated>2019-04-24T14:56:22.062Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>intel提出了摩尔定律，每18个月，芯片的性能就提升一倍。经过这么多年的发展，摩尔定律已经不再适用，究其原因并非芯片厂商无法提升性能，而是功耗太大，大大超过了用户的预期。</p><p>举个例子，2009年全球所有超级计算机中排名第二JUGENE，由73728块四核的PowerPc 450处理器组成，每一颗核心的浮点计算能力为3.4G。而当时同期，NVIDIA的一块售价6000美金的Tesla S1070显卡的浮点计算能力是4.3T。我们再来看看功耗。</p><table><thead><tr><th>参数</th><th>JUGENE</th><th>NVIDIA Tesla S1070</th></tr></thead><tbody><tr><td>计算能力/TFLOPS</td><td>825</td><td>4.3</td></tr><tr><td>体积</td><td>占据整个仓库，有72个机柜</td><td>一台普通个人pc，可以装两块</td></tr><tr><td>功耗/W</td><td>3 000 000</td><td>峰值800</td></tr></tbody></table><p>差距一目了然，这也是为什么最新的超级计算机已经不再完全由gpu组成，而是多块cpu+gpu的异构计算。</p><p>再说回消费级市场，随着机器学习在各行各业的发展，比如直播美颜，基于数据预测的处理等等，要想基于cpu完成实时运算基本不可能。此外还有三维渲染和图形操作，这些操作的运算量巨大，就算是目前顶级的i7都无法胜任。</p><h2 id="为什么gpu比cpu快这么多？"><a href="#为什么gpu比cpu快这么多？" class="headerlink" title="为什么gpu比cpu快这么多？"></a>为什么gpu比cpu快这么多？</h2><p>gpu与cpu计算快这么多的原因有如下几点：</p><ul><li>gpu中用于计算的晶体管比例比cpu多很多</li><li>cpu设计的重点是：复杂的缓存系统、分支预测系统和各种逻辑。</li></ul><p>简单的说，就是gpu本身就是只用来做计算的，而同样面积的cpu芯片中，大部分是用来处理缓存、分支预测和逻辑运算的。自然gpu的计算速度就快很多了。</p><h2 id="gpu的发展阶段"><a href="#gpu的发展阶段" class="headerlink" title="gpu的发展阶段"></a>gpu的发展阶段</h2><p>gpu的历史上经历了四个阶段。</p><table><thead><tr><th>时间</th><th>gpu特点</th></tr></thead><tbody><tr><td>1991年以前</td><td>显示功能在cpu上实现</td></tr><tr><td>1991-2001年</td><td>多为二维图形运算，功能电单一</td></tr><tr><td>2001-2006年</td><td>可编程图形处理器</td></tr><tr><td>2006年至今</td><td>统一着色器模型、gpgpu</td></tr></tbody></table><p>可编程图像处理器推出后，gpu中的着色器和着色语言逐渐被人用来做一些复杂的科学运算。</p><p>直到06年后，统一着色器模型推出后，着色器将不再仅有单一的功能，每一个着色器既可以作为顶点着色器，也可以作为片段着色器，这样使得gpu的计算能力进一步大大提升。</p><blockquote><p>GPGPU代表General Purpose Computing on Graphics Processing Unit。就是图形处理器的通用计算技术。</p></blockquote><h2 id="常见的gpgpu编程技术"><a href="#常见的gpgpu编程技术" class="headerlink" title="常见的gpgpu编程技术"></a>常见的gpgpu编程技术</h2><p>我们常说的gpgpu编程技术有opengl、direct3d、cuda、opencl、metal，未来可能会有越来越多的技术推出。</p><p>我不打算搬出网上的定义，搬出来了我也不记得，没啥意义。</p><p>通俗点讲，有这么几点：</p><ul><li>除了cuda是NVIDIA推出的图形编程接口，只适用于该公司自己的显卡，编程效率更高。</li><li>其他都是软件公司推出的通用接口，比如direct3d是微软推出的，但其跨平台支持并不好，越来越少的人使用。opengl、opencl、metal都是苹果推出的接口和规范。</li><li>opengl的跨平台性最好，支持绝大部分平台和架构。但苹果有计划在自己的设备上慢慢用metal代替opengl。opencl是支持异构资源的计算接口，跨平台和架构性最好，同时支持cpu、gpu、fpga等平台的计算。</li></ul><h2 id="gpu编程的流程"><a href="#gpu编程的流程" class="headerlink" title="gpu编程的流程"></a>gpu编程的流程</h2><p>下图是一个经典gpgpu计算流程。<br><img src="http://tuchuang.servercoder.com/15560935399620.jpg" alt>。</p><p>gpu运算过程都需要经过图中的这些步骤，本文先不详细展开了。</p><h2 id="异构计算"><a href="#异构计算" class="headerlink" title="异构计算"></a>异构计算</h2><p>额外再多提一个异构计算吧。</p><p>前面提到opengl支持市面上很多的平台，尤其是消费级产品，比如pc、android、mac。但它必须要这些设备都带有gpu单元，对于那些没有gpu单元的设备来说，就无能为力了。同时，尽管对android和mac都有支持，但他们的opengl版本不一样，接口调用也不太一样。此外，对于一些嵌入式芯片支持也不是很好。</p><p>苹果在2008年，向Khronos提交了一份跨平台的计算框架，就是我们提到的opencl。它真正做到了平台无关性和操作系统无关性。这个框架在实现的过程中参考了很多cuda的接口设计，所以对于熟悉cuda编程的人来说，上手opencl是很容易的。</p><p>不过，既然是跨平台的方案，那必然在效率上相比于cuda就会稍弱一点，毕竟有一层封装。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>本书很多信息都参考自《GPGPU编程技术  从GLSL、CUDA到OpenCL》，也可以当成是读后感。如有侵权，请联系我删除，谢谢。</p><hr><p>本文链接：<a href="http://www.servercoder.com/2019/04/24/gpu-started/">http://www.servercoder.com/2019/04/24/gpu-started/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;intel提出了摩尔定律，每18个月，芯片的性能就提升一倍。经过这么多年的发展，摩尔定律已经不再适用，究其原因并非芯片厂商无法提升性能，而是
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>详读webrtc的视频统计信息之延迟、抖动与丢包</title>
    <link href="http://www.servercoder.com/2019/04/24/webrtc-statistics/"/>
    <id>http://www.servercoder.com/2019/04/24/webrtc-statistics/</id>
    <published>2019-04-24T04:01:04.746Z</published>
    <updated>2019-04-24T04:03:27.826Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一、前言"><a href="#一、前言" class="headerlink" title="一、前言"></a>一、前言</h2><blockquote><p>这篇文章主要想说明的是WebRTC内部对视频<code>上下行延时、抖动、丢包</code>如何更新，上层又怎么获取到这些统计信息的。对应的<code>WebRTC版本：63</code>。</p></blockquote><h2 id="二、背景"><a href="#二、背景" class="headerlink" title="二、背景"></a>二、背景</h2><blockquote><p>最近在内网情况下测试视频会议，视频下行延时很大，很多时候超过<code>100ms</code>。另外，视频的上下行抖动总是稳定在<code>30~40ms</code>这个区间。这些统计在内网环境下是不正常的，于是决定看看是哪里导致这些问题的。</p><p>在解决这些问题的过程中，也对WebRTC内部视频统计数据做了一次梳理。</p><p>阅读这篇文章之前，最好对RTP、RTCP、SR、RR有一些了解。这里就不过多展开，可以参考以下文章：</p><p>[RTP Data Transfer Protocol][<a href="https://tools.ietf.org/html/rfc3550#section-5" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc3550#section-5</a>]<br>[RTP Control Protocol – RTCP][<a href="https://tools.ietf.org/html/rfc3550#section-6" target="_blank" rel="noopener">https://tools.ietf.org/html/rfc3550#section-6</a>]<br>[RTP/RTSP/RTCP有什么区别][<a href="https://www.zhihu.com/question/20278635/answer/14590945" target="_blank" rel="noopener">https://www.zhihu.com/question/20278635/answer/14590945</a>]</p></blockquote><h2 id="三、综述"><a href="#三、综述" class="headerlink" title="三、综述"></a>三、综述</h2><p>下图是WebRTC内部获取视频统计信息和统计信息如何被更新的流程图：（其中的箭头代表函数调用）</p><p><img src="http://tuchuang.servercoder.com/webrtc-statistics.png" alt="webrtc-statistics"></p><p>上图共有两个大的模块，<strong>如何取</strong>和<strong>如何更新</strong>：</p><h3 id="1-如何取"><a href="#1-如何取" class="headerlink" title="1. 如何取"></a>1. 如何取</h3><p>上面部分“客户端视频数据统计入口”中，左下角的<code>WebRtcVideoChannel::GetStats</code>是WebRTC对外暴露的获取统计信息的入口，视频的上下行统计数据最终分别使用右上角<code>SendStatisticsProxy::stats_</code>、<code>ReceiveStatisticsProxy::stats_</code>和<code>CallStats::avg_rtt_ms_</code>来填充返回。</p><h3 id="2-如何更新"><a href="#2-如何更新" class="headerlink" title="2. 如何更新"></a>2. 如何更新</h3><p>下面部分“延时、抖动、丢包更新流程”部分，从网络接收到RTP/RTCP之后，使用三个不同颜色代表三种统计信息的更新流程，比如红色代表下行抖动/丢包更新流程、蓝色代表RTT的更新流程等。</p><p>统计信息大多不是由一条调用流程完成的（这就是下文会说到的“阶段”），会有几次类似缓冲区的“中转”，然后由另外的线程或函数继续做统计信息的整理，最终达到上一步的<code>SendStatisticsProxy::stats_</code>、<code>ReceiveStatisticsProxy::stats_</code>和<code>CallStats::avg_rtt_ms_</code>，等待上层获取。</p><h2 id="四、几个统计信息详细介绍"><a href="#四、几个统计信息详细介绍" class="headerlink" title="四、几个统计信息详细介绍"></a>四、几个统计信息详细介绍</h2><h3 id="1、延时"><a href="#1、延时" class="headerlink" title="1、延时"></a>1、延时</h3><blockquote><p> 这里统计的延时指的是往返延时 rtt。<code>WebRTC使用SR/RR来计算rtt</code>。</p></blockquote><h4 id="1-延时的计算"><a href="#1-延时的计算" class="headerlink" title="(1) 延时的计算"></a>(1) 延时的计算</h4><h5 id="1-SR和RR报文格式"><a href="#1-SR和RR报文格式" class="headerlink" title="1) SR和RR报文格式"></a>1) SR和RR报文格式</h5><table><thead><tr><th>Sender Report RTCP Packet</th><th>Receiver Report RTCP Packet</th></tr></thead><tbody><tr><td><img src="http://tuchuang.servercoder.com/sr.png" alt="s"></td><td><img src="http://tuchuang.servercoder.com/rr.png" alt="r"></td></tr></tbody></table><h5 id="2-计算rtt"><a href="#2-计算rtt" class="headerlink" title="2) 计算rtt"></a>2) 计算rtt</h5><blockquote><p>以下流程通过结合SR/RR包报文格式，浏览<code>RTCPReceiver::HandleReceiverReport</code>、<code>RTCPReceiver::HandleReportBlock</code>、<code>ModuleRtpRtcpImpl::SendCompoundRTCP</code>、<code>RTCPSender::BuildSR</code>、<code>RTCPSender::BuildRR</code>函数。前面2个函数是接收端计算rtt，后面3个函数是对端在构造RR时LSR/DLSR如何设置的。</p></blockquote><ul><li>首先，发送端构造SR时，<code>sender info</code>部分的NTP字段被设置为当前ntp时间戳；</li><li>接收端收到最新的SR之后，使用<code>last_received_sr_ntp_</code>字段记录当前ntp时间戳；</li><li>接收端构造RR时，设置RR的DLSR字段为<code>当前ntp时间戳 - last_received_sr_ntp_</code>，之后发出RR包；</li><li>发送端在接收到RR包之后，记录RR包到达时间A；</li><li>使用公式 <code>A - LSR - DLSR</code> 计算rtt。</li></ul><h5 id="3-用一个图描述上述RTT计算流程"><a href="#3-用一个图描述上述RTT计算流程" class="headerlink" title="3) 用一个图描述上述RTT计算流程"></a>3) 用一个图描述上述RTT计算流程</h5><p><img src="http://tuchuang.servercoder.com/sr-rr-rtt.png" alt="sr-rr-rtt"></p><blockquote><p>SR与RR的个数并不完全相同，因为RR并不是对SR的回应，它们的发送各自独立；另外丢包也会导致一部分SR/RR没有被对方接收。因此上图中，SR和RR传输中，实线代表发了一次SR/RR，并且被被对方接收了。这里想说明的是：<strong>即便SR或RR丢失一部分，只要发送端收到了RR，它总能计算出rtt，因为RR中使用的LSR和DLSR字段都是从最近一次收到的SR中取到的。</strong></p></blockquote><h4 id="2-延时的更新流程"><a href="#2-延时的更新流程" class="headerlink" title="(2) 延时的更新流程"></a>(2) 延时的更新流程</h4><blockquote><p>下文所说的第一阶段、第二阶段等，都是指 <strong>数据从一个位置转移到另一个位置的过程，或者说是一次推或拉模式</strong>。比如：F1函数把数据从A点转移到B点就返回了，F2函数把数据从B点转移到C点就返回了，那A-&gt;B就是第一阶段，B-&gt;C就是第二阶段。如下：</p></blockquote><p><img src="http://tuchuang.servercoder.com/A-B-C%E6%95%B0%E6%8D%AE%E8%BD%AC%E7%A7%BB.png" alt="A-B-C数据转移"></p><h5 id="1-rtt统计第一阶段"><a href="#1-rtt统计第一阶段" class="headerlink" title="1) rtt统计第一阶段"></a>1) rtt统计第一阶段</h5><p>由上文可知：从RR可以计算出往返延时rtt，这个rtt最终保存在<code>RTCPReceiver::received_report_blocks_</code>。</p><p><img src="http://tuchuang.servercoder.com/rtt%E6%9B%B4%E6%96%B0%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5.png" alt="rtt更新第一阶段"></p><h5 id="2-rtt统计第二阶段"><a href="#2-rtt统计第二阶段" class="headerlink" title="2) rtt统计第二阶段"></a>2) rtt统计第二阶段</h5><p><code>ModuleRtpRtcpImpl::Process</code>会定时把rtt从<code>RTCPReceiver::received_report_blocks_</code>更新到<code>CallStats::reports_</code>，这个更新过程，<code>CallStats::reports_</code>中每个rtt都会与一个更新时间戳绑定。参考<code>CallStats::OnRttUpdate</code> 函数。</p><p><img src="http://tuchuang.servercoder.com/rtt%E6%9B%B4%E6%96%B0%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5.png" alt="rtt更新第二阶段"></p><h5 id="3-rtt统计第三阶段"><a href="#3-rtt统计第三阶段" class="headerlink" title="3) rtt统计第三阶段"></a>3) rtt统计第三阶段</h5><p><code>CallStats</code>继承<code>Module</code>，<code>CallStats::Process</code>函数会定时做以下三个步骤：</p><ul><li><p>根据第二阶段绑定的时间戳，清理掉 reports_ 中距当前时间1.5s以前的rtt；</p></li><li><p>计算1.5s内的平均rtt；</p></li><li><p>使用平均rtt，更新 avg_rtt<em>ms</em> 成员；</p></li></ul><p>  <img src="http://tuchuang.servercoder.com/rtt%E6%9B%B4%E6%96%B0%E7%AC%AC%E4%B8%89%E9%98%B6%E6%AE%B5.png" alt="rtt更新第三阶段"></p><h4 id="3-获取延时"><a href="#3-获取延时" class="headerlink" title="(3) 获取延时"></a>(3) 获取延时</h4><p>调用<code>CallStats::avg_rtt_ms</code>函数获取rtt时，直接返回avg_rtt<em>ms</em> ;</p><h3 id="2、下行抖动和丢包"><a href="#2、下行抖动和丢包" class="headerlink" title="2、下行抖动和丢包"></a>2、下行抖动和丢包</h3><blockquote><p>下行抖动和丢包，通过在接收端根据收到的RTP包来计算和更新。</p></blockquote><h4 id="1-抖动和丢包的计算"><a href="#1-抖动和丢包的计算" class="headerlink" title="(1) 抖动和丢包的计算"></a>(1) 抖动和丢包的计算</h4><h5 id="1-抖动定义"><a href="#1-抖动定义" class="headerlink" title="1) 抖动定义"></a>1) 抖动定义</h5><p>抖动被定义为：一对数据包在接收端与发送端的数据包时间间距之差。如下：</p><p><img src="http://tuchuang.servercoder.com/%E6%8A%96%E5%8A%A8%E5%AE%9A%E4%B9%89.png" alt="抖动定义"></p><p>如果Si代表第i个包的发送时间戳，Ri代表第i个包的接收时间戳。Sj、Rj同理。<br><code>抖动(i, j)</code> = <code>|(Rj - Ri) - (Sj - Si)|</code>  =  <code>|(Rj - Sj) - (Ri - Si)|</code></p><p>WebRTC为了统一抖动，并且为了很好的降噪、降低突发抖动的影响，把上面的<code>抖动(i, j)</code>定义为<code>D(i, j)</code>，<code>抖动J(i)</code>定义为:<br><code>J(i) = J(i-1) + (|D(i-1, i)| - J(i - 1)) / 16</code></p><p>我虽然看不出J(i)和D(i)的关系，但是<code>D(i-1, j)</code>是唯一引起<code>J(i)</code>变化的因素，是需要重点关注的。</p><h5 id="2-抖动计算存在的问题："><a href="#2-抖动计算存在的问题：" class="headerlink" title="2) 抖动计算存在的问题："></a>2) 抖动计算存在的问题：</h5><p>RTP报文头部，有timestamp字段，该字段用来表示该RTP包所属帧的<code>capture time</code>。接收RTP包时如果记录接收时间戳，再根据头部的<code>timestamp</code>字段，D(i, j)就可以计算出来，J也就有了。（事实上webrtc原本也是这样干的，而且这种方式计算的抖动还对外暴露，可以参考<code>StreamStatisticianImpl::UpdateJitter</code>函数）</p><p>但是这样计算抖动是存在问题的：<strong>每一帧的视频数据放进多个RTP包之后，这些RTP包的头部timestamp字段都是一样的（都是帧的capture time），但是实际发送时间不一样，到达时间也不同。</strong></p><h5 id="3-如何正确计算抖动："><a href="#3-如何正确计算抖动：" class="headerlink" title="3) 如何正确计算抖动："></a>3) 如何正确计算抖动：</h5><p>计算D(i, j)时，Si不能只使用RTP timestamp，而是应该使用该RTP实际发送到网络的时间戳。这种抖动被命名为<code>jitter_q4_transmission_time_offset</code>，意为考虑了transmission_time_offset的jitter。</p><ul><li><strong>a. transmission_time_offset是什么?</strong></li></ul><blockquote><p>transmission_time_offset是一段时间间隔，该时间间隔代表属于同一帧的RTP的<code>实际发送时间</code>距离帧的<code>capture time</code>的 <strong>偏移量</strong> 。下图是对transmission_offset_time的解释：</p></blockquote><p><img src="http://tuchuang.servercoder.com/transmission_offset.png" alt="transmission_offset"></p><blockquote><p>其中，箭头代表一个RTP，发送端的竖线代表时间轴，虚线代表帧的capture time。</p><p>最开始三个RTP包在距离capture time <code>offset1</code>时间之后发送到网络，因此这三个RTP包的transmission_time_offset应该是offset1。同理第四个RTP包的transmission_time_offset应该是offset2，第五个RTP包的transmission_time_offset应该是offset3。</p></blockquote><ul><li><strong>b. transmission_time_offset在RTP包的哪里放着?</strong></li></ul><p>transmission_time_offset存在于RTP的扩展头部，设置该扩展头可以参考<code>RTPSender::SendToNetwork</code>函数，但使用之前该扩展头之前需要注册，否则在设置transmission_time_offset扩展头会失败。</p><p>下面的代码段是WebRTC中<code>D(i, j)</code>的计算：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Extended jitter report, RFC 5450.</span></span><br><span class="line"><span class="comment">// Actual network jitter, excluding the source-introduced jitter.</span></span><br><span class="line"><span class="keyword">int32_t</span> time_diff_samples_ext =</span><br><span class="line">  (receive_time_rtp - last_receive_time_rtp) -</span><br><span class="line">  ((header.timestamp +</span><br><span class="line">    header.extension.transmissionTimeOffset) -</span><br><span class="line">   (last_received_timestamp_ +</span><br><span class="line">    last_received_transmission_time_offset_));</span><br></pre></td></tr></table></figure><p>其中：</p><blockquote><ul><li><code>receive_time_rtp</code> 代表当前RTP的到达时间戳；</li><li><code>last_receive_time_rtp</code> 是上一个RTP到达时记录的时间戳；</li><li><code>header.timestamp + header.extension.transmissionTimeOffset</code> 前者是capture time，后者是对应的transmission time offset，两者相加代表该RTP实际发送到网络的时间戳；</li><li><code>last_received_timestamp_ + last_received_transmission_time_offset_</code> 含义同上，但是代表的是<strong>上一个</strong>RTP的实际发送到网络的时间戳；</li></ul></blockquote><h4 id="2-下行抖动的更新流程"><a href="#2-下行抖动的更新流程" class="headerlink" title="(2) 下行抖动的更新流程"></a>(2) 下行抖动的更新流程</h4><h5 id="1-抖动统计第一阶段"><a href="#1-抖动统计第一阶段" class="headerlink" title="1) 抖动统计第一阶段"></a>1) 抖动统计第一阶段</h5><p>接收端收到的RTP包，会经过<code>StreamStatisticianImpl::UpdateJitter</code>函数，该函数内部会计算经过这个RTP包之后的抖动值，并更新到成员<code>jitter_q4_transmission_time_offset_</code>成员中。</p><p><img src="http://tuchuang.servercoder.com/%E6%8A%96%E5%8A%A8%E6%9B%B4%E6%96%B0%E7%AC%AC%E4%B8%80%E9%98%B6%E6%AE%B5.png" alt="抖动更新第一阶段"></p><h5 id="2-抖动统计第二阶段"><a href="#2-抖动统计第二阶段" class="headerlink" title="2) 抖动统计第二阶段"></a>2) 抖动统计第二阶段</h5><p><code>ModuleRtpRtcpImpl::Process</code>会定时发送RR，在构建RR的Report Block时，会搜集本地接收报告并把第一阶段保存的<code>jitter_q4_transmission_time_offset_</code>信息更新到<code>ReceiveStatisticsProxy::stats_</code> 。</p><p><img src="http://tuchuang.servercoder.com/%E6%8A%96%E5%8A%A8%E6%9B%B4%E6%96%B0%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5.png" alt="抖动更新第二阶段"></p><h4 id="3-下行丢包的更新流程"><a href="#3-下行丢包的更新流程" class="headerlink" title="(3) 下行丢包的更新流程"></a>(3) 下行丢包的更新流程</h4><h5 id="1-丢包统计第一阶段"><a href="#1-丢包统计第一阶段" class="headerlink" title="1) 丢包统计第一阶段"></a>1) 丢包统计第一阶段</h5><p>接收端收到的RTP包，会经过<code>StreamStatisticianImpl::UpdateCounters</code> 函数，在该函数内部，会累加接收到的RTP包的个数和重传包的个数，以及当前收到的最大的sequence。</p><h5 id="2-丢包统计第二阶段"><a href="#2-丢包统计第二阶段" class="headerlink" title="2) 丢包统计第二阶段"></a>2) 丢包统计第二阶段</h5><p>下图是WebRTC内部计算下行丢包：</p><p><img src="http://tuchuang.servercoder.com/%E4%B8%A2%E5%8C%85%E8%AE%A1%E7%AE%97.png" alt="丢包计算"></p><p>丢包率更新的周期是发送一次RR，在发送RR时，会根据第一阶段记录的数据统计丢包，丢包根据下面的公式：</p><p><code>fraction_lost</code> = <code>RTP包丢失个数</code> / <code>期望接收的RTP包个数</code></p><blockquote><p>其中：</p><p><code>包丢失个数</code> = <code>期望接收的RTP包个数</code> - <code>实际收到的RTP包个数</code></p><p><code>期望接收的RTP包个数</code> = <code>当前最大sequence</code> - <code>上次最大sequence</code></p><p><code>实际收到的RTP包个数</code> = <code>正常有序RTP包</code> + <code>重传包</code></p></blockquote><p>计算出来的丢包，连同抖动一起被更新到<code>ReceiveStatisticsProxy::stats_</code>。</p><p><img src="http://tuchuang.servercoder.com/%E4%B8%A2%E5%8C%85%E6%9B%B4%E6%96%B0%E7%AC%AC%E4%BA%8C%E9%98%B6%E6%AE%B5.png" alt="丢包更新第二阶段"></p><h4 id="3-获取下行抖动和丢包"><a href="#3-获取下行抖动和丢包" class="headerlink" title="(3) 获取下行抖动和丢包"></a>(3) 获取下行抖动和丢包</h4><p>下行抖动和丢包最终会从<code>ReceiveStatisticsProxy::stats_</code> 获取。</p><h3 id="3、上行抖动和丢包"><a href="#3、上行抖动和丢包" class="headerlink" title="3、上行抖动和丢包"></a>3、上行抖动和丢包</h3><blockquote><p>下行抖动和丢包，从对方发来的RR包中获取。RR包格式参考上文链接。</p></blockquote><h4 id="1-上行抖动和丢包的更新流程"><a href="#1-上行抖动和丢包的更新流程" class="headerlink" title="(1) 上行抖动和丢包的更新流程"></a>(1) 上行抖动和丢包的更新流程</h4><p>本地上行抖动和丢包，就是对端下行抖动和丢包，对端按照上面介绍的方式计算下行抖动和丢包，然后通过RR返回。</p><p>从RR获取抖动和丢包，没有太多阶段，只有一次<code>推</code>过程。接收端在收到RR之后，就把内部的抖动和丢包更新到<code>SendStatisticsProxy::stats_</code>中，这里就是客户端主动获取上行抖动和丢包时最终的数据源。</p><h4 id="2-获取上行抖动和丢包"><a href="#2-获取上行抖动和丢包" class="headerlink" title="(2) 获取上行抖动和丢包"></a>(2) 获取上行抖动和丢包</h4><p>上行抖动和丢包最终会从<code>SendStatisticsProxy::stats_</code> 获取。</p><h2 id="五、最后"><a href="#五、最后" class="headerlink" title="五、最后"></a>五、最后</h2><p>以上是最近对WebRTC视频统计数据的了解，希望能对有需要的人有所帮助。如有不对的地方，欢迎指正！！</p><hr><p>本文链接：<a href="http://www.servercoder.com/2019/04/24/webrtc-statistics/">http://www.servercoder.com/2019/04/24/webrtc-statistics/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;一、前言&quot;&gt;&lt;a href=&quot;#一、前言&quot; class=&quot;headerlink&quot; title=&quot;一、前言&quot;&gt;&lt;/a&gt;一、前言&lt;/h2&gt;&lt;blockquote&gt;
&lt;p&gt;这篇文章主要想说明的是WebRTC内部对视频&lt;code&gt;上下行延时、抖动、丢包&lt;/code&gt;如何更
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>TLS应用开发相关知识</title>
    <link href="http://www.servercoder.com/2019/02/17/tls-application/"/>
    <id>http://www.servercoder.com/2019/02/17/tls-application/</id>
    <published>2019-02-17T12:40:56.106Z</published>
    <updated>2019-02-17T12:40:56.106Z</updated>
    
    <content type="html"><![CDATA[<h1 id="证书相关"><a href="#证书相关" class="headerlink" title="证书相关"></a>证书相关</h1><p>TLS（Transport Layer Security）意为传输层安全协议，目前较常见的实现是OpenSSL, 而BoringSSL是google基于OpenSSL创建的，只是为了自己的需要，并不是通用的实现，所以如无必要，我们还是直接使用OpenSSL比较好。<br>TLS是基于X.509证书标准的，其标准是RFC5280。</p><h2 id="证书格式"><a href="#证书格式" class="headerlink" title="证书格式"></a>证书格式</h2><p>目前支持两种格式：PEM和DER。<br>其中DER是二进制格式，而PEM则是在DER的基础上进行BASE64编码后，并存放在存放在”—–BEGIN CERTIFICATE—–”和”—–END CERTIFICATE—–”之中。<br>查看PEM格式证书信息的命令：openssl x509 -in certificate.pem -text -noout<br>查看DER格式证书信息的命令：openssl x509 -in certificate.der -inform der -text -noout</p><h2 id="证书扩展名"><a href="#证书扩展名" class="headerlink" title="证书扩展名"></a>证书扩展名</h2><p>这是比较误导人的地方,虽然我们已经知道有PEM和DER这两种编码格式,但文件扩展名并不一定就叫”PEM”或者”DER”,常见的扩展名除了PEM和DER还有以下这些,它们除了编码格式可能不同之外,内容也有差别,但大多数都能相互转换编码格式.</p><ol><li>CRT - CRT应该是certificate的三个字母,其实还是证书的意思,常见于*NIX系统,有可能是PEM编码,也有可能是DER编码,大多数应该是PEM编码,相信你已经知道怎么辨别.</li><li>CER - 还是certificate,还是证书,常见于Windows系统,同样的,可能是PEM编码,也可能是DER编码,大多数应该是DER编码.</li><li>KEY - 通常用来存放一个公钥或者私钥,并非X.509证书,编码同样的,可能是PEM,也可能是DER.<br>查看KEY的办法:openssl rsa -in mykey.key -text -noout<br>如果是DER格式的话,同理应该这样了:openssl rsa -in mykey.key -text -noout -inform der</li><li>CSR - Certificate Signing Request,即证书签名请求,这个并不是证书,而是向权威证书颁发机构获得签名证书的申请,其核心内容是一个公钥(当然还附带了一些别的信息),在生成这个申请的时候,同时也会生成一个私钥,私钥要自己保管好.做过iOS APP的朋友都应该知道是怎么向苹果申请开发者证书的吧.<br>查看的办法:openssl req -noout -text -in my.csr (如果是DER格式的话照旧加上-inform der,这里不写了)</li><li>PFX/P12 - predecessor of PKCS#12,对*nix服务器来说,一般CRT和KEY是分开存放在不同文件中的,但Windows的IIS则将它们存在一个PFX文件中,(因此这个文件包含了证书及私钥)这样会不会不安全？应该不会,PFX通常会有一个”提取密码”,你想把里面的东西读取出来的话,它就要求你提供提取密码,PFX使用的时DER编码,如何把PFX转换为PEM编码？<br>openssl pkcs12 -in for-iis.pfx -out for-iis.pem -nodes<br>这个时候会提示你输入提取代码. for-iis.pem就是可读的文本.<br>生成pfx的命令类似这样:openssl pkcs12 -export -in certificate.crt -inkey privateKey.key -out certificate.pfx -certfile CACert.crt<br>其中CACert.crt是CA(权威证书颁发机构)的根证书,有的话也通过-certfile参数一起带进去.这么看来,PFX其实是个证书密钥库.</li><li>JKS - 即Java Key Storage,这是Java的专利,跟OpenSSL关系不大,利用Java的一个叫”keytool”的工具,可以将PFX转为JKS,当然了,keytool也能直接生成JKS,不过在此就不多表了.<h2 id="获得证书"><a href="#获得证书" class="headerlink" title="获得证书"></a>获得证书</h2>有两种方式：申请或者自签名，调试时自签名就够了。</li><li><p>向权威证书颁发机构申请证书<br>用这命令生成一个csr: openssl req -newkey rsa:2048 -new -nodes -keyout my.key -out my.csr<br>把csr交给权威证书颁发机构,权威证书颁发机构对此进行签名,完成.保留好csr,当权威证书颁发机构颁发的证书过期的时候,你还可以用同样的csr来申请新的证书,key保持不变.</p></li><li><p>生成自签名的证书<br>openssl req -newkey rsa:2048 -new -nodes -x509 -days 3650 -keyout key.pem -out cert.pem<br>在生成证书的过程中会要你填一堆的东西,其实真正要填的只有Common Name,通常填写你服务器的域名,如”yourcompany.com”,或者你服务器的IP地址,其它都可以留空的.<br>生产环境中还是不要使用自签的证书,否则浏览器会不认,或者如果你是企业应用的话能够强制让用户的浏览器接受你的自签证书也行.向权威机构要证书通常是要钱的,但现在也有免费的,仅仅需要一个简单的域名验证即可.有兴趣的话查查”沃通数字证书”.</p><h1 id="最佳实践"><a href="#最佳实践" class="headerlink" title="最佳实践"></a>最佳实践</h1></li></ol><h1 id="开发流程"><a href="#开发流程" class="headerlink" title="开发流程"></a>开发流程</h1><h1 id="wireshark抓包"><a href="#wireshark抓包" class="headerlink" title="wireshark抓包"></a>wireshark抓包</h1><h1 id="参考文档"><a href="#参考文档" class="headerlink" title="参考文档"></a>参考文档</h1><ol><li>证书的相关知识转载自：<a href="https://www.cnblogs.com/guogangj/p/4118605.html" target="_blank" rel="noopener">那些证书相关的玩意儿(SSL,X.509,PEM,DER,CRT,CER,KEY,CSR,P12等)</a></li></ol><hr><p>本文链接：<a href="http://www.servercoder.com/2019/02/17/tls-application/">http://www.servercoder.com/2019/02/17/tls-application/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;证书相关&quot;&gt;&lt;a href=&quot;#证书相关&quot; class=&quot;headerlink&quot; title=&quot;证书相关&quot;&gt;&lt;/a&gt;证书相关&lt;/h1&gt;&lt;p&gt;TLS（Transport Layer Security）意为传输层安全协议，目前较常见的实现是OpenSSL, 而Bori
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>tcp通信应用的安全如何保证</title>
    <link href="http://www.servercoder.com/2018/05/17/tcp-safe/"/>
    <id>http://www.servercoder.com/2018/05/17/tcp-safe/</id>
    <published>2018-05-16T16:06:27.033Z</published>
    <updated>2018-05-16T16:15:33.048Z</updated>
    
    <content type="html"><![CDATA[<h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><p>只要是网络通信，就必须要考虑网络安全，本文主要阐述的是TCP通信业务有可能遇到的问题和解决办法，http在通信层面的安全与tcp类似，但是业务层面的的安全要考虑的问题就太多了，比如session劫持、sql注入、xss攻击等等，这一块和udp的业务安全后续再单独总结。</p><h1 id="网络攻击和防御"><a href="#网络攻击和防御" class="headerlink" title="网络攻击和防御"></a>网络攻击和防御</h1><h2 id="1-传输层截获、篡改、伪造"><a href="#1-传输层截获、篡改、伪造" class="headerlink" title="1. 传输层截获、篡改、伪造"></a>1. 传输层截获、篡改、伪造</h2><p>防御：tls<br>我们谈论网络安全的时候，常常会从如下四种问题考虑：</p><ol><li>中断。攻击者有意中断他人的网络通信。</li><li>截获。攻击者非法窃取他人正在通信的内容。</li><li>篡改。攻击者恶意篡改他人正在通信的内容。</li><li>伪造。攻击者伪造信息在网络上传输。比如常见的重放攻击，摘要算法挡不住重放攻击。</li></ol><p>对于中断类的攻击，大多都是从传输层中断，最终的目的是该连接无法正常通信。对于客户端和服务端来说，都无法轻易感知，因而大多中断类型的问题，都无法有效防范和解决。</p><p>对于截获、篡改、伪造来说，tls是最好的解决办法。tls的安全目标主要包括如下几个：</p><ul><li>认证性 – 数字签名防止伪造。</li><li>机密性 – 所有数据都基于证书中的公钥加密，是不堆成加密的一部分。</li><li>完整性 – 借助消息认证码（MAC）保障数据完整性，防止消息篡改。</li><li>重放保护 – 通过使用隐式序列号防止重放攻击。</li></ul><p>值得注意的是，tls有多个版本，tls1.0，tls1.1，tls1.2，安全起见，建议总是优先使用最新版本。</p><p><strong>tls置于反向代理nginx处，还是业务服务器处？</strong><br>如果条件允许，建议直接置于反向代理处，避免每台业务服务器都单独配置证书。但这带来了其他问题，tls的完整性没法得到保障，因为反向代理到业务服务器的通信是tcp的了，需自行考虑数据完整性校验；其次是业务服务器（不考虑接入层）最好是无状态可任意调度的，不然得为每台服务器单独配置nginx的端口。</p><h2 id="2-tls中间人攻击"><a href="#2-tls中间人攻击" class="headerlink" title="2. tls中间人攻击"></a>2. tls中间人攻击</h2><p>防御：客户端内置证书、浏览器自行辨别。<br>上面提到了很多tls的好处，https也类似。但这并不意味着tls就是万能的了，因为我们还需要保证tls证书的安全。<br>路由器、网关、DNS服务器都可以干这个事情，它们将原先的请求转发给伪造方，并将伪造方的证书放回给客户端，同时假装自己是客户端与真正的服务器通信。</p><p>对于chrome浏览器而言，它内置了信任的根证书机构。默认认为只有根证书颁发的证书，同时该证书颁发给该域名的，才是安全的。任何自己生成的，或是第三方机构生成的证书，它都认为不安全，比如12306。遇到这种情况，只能由用户自己辨别，还好chrome已经强制将非https和证书不对的网站标记为不安全了。</p><p>而对于app而言，并不能很直观地查看网址是否安全，但我们可以提前将证书打包进app，每次建立连接时与服务器的证书比对一下，也能尽可能防御tls的中间人攻击。不过，app需要提前开发证书更新的接口。</p><p>app内置证书其实也并不是完美的，因为app能被人反编译，也就以为着打包的证书可以被篡改。</p><h2 id="3-ddos攻击"><a href="#3-ddos攻击" class="headerlink" title="3. ddos攻击"></a>3. ddos攻击</h2><p>防御：防火墙配置<br>dos即deny of service，d-dos即distributed deny of service，也叫洪水攻击。通俗的讲，就是发动大量的设备或并发请求，消耗掉服务器的带宽或资源，导致服务器不再接受服务。<br>如果没有处理这些问题的经验，就把问题丢给阿里云吧，阿里云的服务能搞定大部分的问题。同时我们的应用程序要做好隔离、快速上下线的能力。</p><h2 id="4-syn攻击"><a href="#4-syn攻击" class="headerlink" title="4. syn攻击"></a>4. syn攻击</h2><p>防御：配置tcp相关的系统参数。<br>准确的说，syn攻击也属于ddos攻击的一部分。操作起来，就是同一时间发动大量的tcp的syn请求，使得服务器中有大量的tcp处于半连接的状态。此时每个连接都要消耗一个TCB（传输控制块）的内存，同时还需要sync ack重传消耗cpu和网络资源。<br>解决办法就是配置防火墙，同时修改syn_recv队列、限制syn鬓发、减少sync-ack的重发。<br>具体的解决办法参见<a href="Linux安全之SYN攻击原理及处理">Linux安全之SYN攻击原理及处理</a></p><h2 id="5-RST-和-FIN-攻击"><a href="#5-RST-和-FIN-攻击" class="headerlink" title="5. RST 和 FIN 攻击"></a>5. RST 和 FIN 攻击</h2><p>防御：防火墙配置<br>如果FIN/RST 报文速率超过阈值会启动会话检查，当清洗设备检查到FIN/RST报文没有命中会话，则直接丢弃。<br>如果清洗设备检查到FIN/RST报文命中会话，则检查会话创建的原因，如果会话是由SYN或者SYN-ACK创建的，则允许报文通过，如果会话是由其他报文创建的（如ACK报文）则查看报文的序列号，若正确则放行，否则丢弃。</p><h2 id="6-服务端数据安全"><a href="#6-服务端数据安全" class="headerlink" title="6. 服务端数据安全"></a>6. 服务端数据安全</h2><p>防御： 端到端加密<br>前面一直讨论的是客户端与服务端通信时的安全，可还有一种情况，服务提供商可随意查阅信息，比如qq。要想解决这个问题，端到端加密是目前唯一的解决办法，客户端自行交换公钥。<br>但网络安全法第21条似乎不太允许国内运营商这样做，它要求服务端需要保存相应的日志、信息等。尽管没有明确说明所有数据后台可查询，但从qq、微信、米聊等软件来看，它们都没有采用端到端加密，估计就是因为这个吧。</p><hr><p>本文链接：<a href="http://www.servercoder.com/2018/05/17/tcp-safe/">http://www.servercoder.com/2018/05/17/tcp-safe/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h1 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h1&gt;&lt;p&gt;只要是网络通信，就必须要考虑网络安全，本文主要阐述的是TCP通信业务有可能遇到的问题和解决办法，http在通信层面的安全与tcp类似，但是业
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>是时候使用1.1.1.1作为DNS服务器了吗？</title>
    <link href="http://www.servercoder.com/2018/05/13/should-we-use-1111-as-dns-server/"/>
    <id>http://www.servercoder.com/2018/05/13/should-we-use-1111-as-dns-server/</id>
    <published>2018-05-13T01:29:44.718Z</published>
    <updated>2018-05-13T15:19:42.010Z</updated>
    
    <content type="html"><![CDATA[<p>18年4月1号，cloudflare发布了其公开的DNS解析服务器，并宣称它是最快的、最安全的DNS服务。那是不是意味着我们就马上就可以切换DNS服务器了呢？</p><p>未必，起码大陆地区暂时还不够快。</p><h2 id="1-1-1-1优点"><a href="#1-1-1-1优点" class="headerlink" title="1.1.1.1优点"></a>1.1.1.1优点</h2><p>本文并不是DNS的科普文章，也不会花很多笔墨讲解DNS解析的过程，我前前后后看过很多遍DNS相关原理，可我工作中跟DNS公共服务器打交道的机会几乎没有，所以看完又忘。如果想了解DNS基本知识的，可移步至阮一峰的<a href="http://www.ruanyifeng.com/blog/2016/06/dns.html" target="_blank" rel="noopener">《DNS 原理入门》</a>。</p><p>市面上公共DNS不少，ibm、google、百度、阿里、腾讯、114、还有各大运营商自己的DNS服务器。那我们为什么还要评估1.1.1.1呢？<br>很简单，因为他们大多都是流氓，DNS劫持还算小打小闹，高级一点的给你弄点http劫持，更有甚者还给你强行安装软件。</p><p>1.1.1.1的优点：</p><ol><li>快。<br>Cloudflare在全球有超过1000台服务器。我们来看看权威DNS性能测试平台的数据。<br><img src="http://p8eh0n2r4.bkt.clouddn.com/18-5-8/97673626.jpg" alt="img"><br>有兴趣的同学可以看一下，<a href="https://www.dnsperf.com/#!dns-resolvers" target="_blank" rel="noopener">DNSPerf</a>测试的全球的DNS服务器，确实1.1.1.1在全球几大洲的平均速度都是最快的。</li><li>安全。<br> 我们上网时或多或少会遇到下面这些情况：<br> <strong>DNS劫持</strong>：访问公司A的网站，结果打开的却是A的竞争对手B的网站，或者索性就不给打开。<br> <strong>http劫持</strong>：DNS劫持算低级的，明白人一眼就能看出问题来，所以现在很少有DNS服务器提供商做DNS劫持了，现在一般都是http劫持。简单的说，就是所有请求都正常响应，但是会你的网页里面多加一段脚本，比如右下角的广告啊。遇到这种事情，除了浏览器安装AdBlocks插件屏蔽广告以外，根本没办法防御。<br> <strong>数据泄露</strong>：http劫持是明枪，数据泄露就是暗箭了。我想很多人都有这样的精力，百度搜索一下某某东西，结果打开京东或者淘宝，立马就能自动推荐给你了。这也还好，毕竟给你提供了便利，有点人工智能的味道，只要你不要搜索一些隐私产品，不然就尴尬了。可如果用来做坏事，想想都可怕。目前大部分的公开DNS服务器都在收集这些数据。<br> <br> 而1.1.1.1则宣称自己并不保存任何数据，就连日志数据也仅仅只是保留24小时。相比其他DNS服务提供商，这样已经很有良心了。</li></ol><h2 id="那我们该怎么办？"><a href="#那我们该怎么办？" class="headerlink" title="那我们该怎么办？"></a>那我们该怎么办？</h2><p>既然1.1.1.1又快又安全，那还等什么，能赶紧用上吗？<br>很显然，大陆目前还不行。究其原因，我想主要是1.1.1.1还没在大陆部署节点有关。尽管1.1.1.1的公司cloudflare与百度很早就建立了合作伙伴关系，用于改善国内访问cloudflare产品的访问速度，但很明显该合作不涉及1.1.1.1，我个人觉得未来可能也不太可能通过百度的合作来提升访问速度，因为百度有自己的公开DNS服务，他们还靠这个挣钱呢。<br>其次，很多交换机默认使用了1.1.1.1作为默认ip，尤其是企业交换机。要想能使用1.1.1.1还需要坐等交换机的升级。</p><p>总的来说，要想在大陆使用上1.1.1.1可能得等到半年以后，至于最终是否能落地，还是取决于cloudflare是否会考虑大陆几亿网民的需求了。</p><h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><ol><li><a href="https://www.cloudflare.com/learning/dns/what-is-1.1.1.1/" target="_blank" rel="noopener">https://www.cloudflare.com/learning/dns/what-is-1.1.1.1/</a><br></li></ol><hr><p>本文链接：<a href="http://www.servercoder.com/2018/05/13/should-we-use-1111-as-dns-server/">http://www.servercoder.com/2018/05/13/should-we-use-1111-as-dns-server/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;p&gt;18年4月1号，cloudflare发布了其公开的DNS解析服务器，并宣称它是最快的、最安全的DNS服务。那是不是意味着我们就马上就可以切换DNS服务器了呢？&lt;/p&gt;
&lt;p&gt;未必，起码大陆地区暂时还不够快。&lt;/p&gt;
&lt;h2 id=&quot;1-1-1-1优点&quot;&gt;&lt;a href=&quot;#
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>服务发现框架选型，Consul还是Zookeeper还是etcd</title>
    <link href="http://www.servercoder.com/2018/03/30/consul-vs-zookeeper-etcd/"/>
    <id>http://www.servercoder.com/2018/03/30/consul-vs-zookeeper-etcd/</id>
    <published>2018-03-30T12:18:27.708Z</published>
    <updated>2018-03-30T12:28:15.624Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>本文并不介绍服务发现的基本原理。除了一致性算法之外，其他并没有太多高深的算法，网上的资料很容易让大家明白上面是服务发现。<br>想直接查看结论的同学，请直接跳到文末。<br>目前，市面上有非常多的服务发现工具，《<a href="http://jasonwilder.com/blog/2014/02/04/service-discovery-in-the-cloud/" target="_blank" rel="noopener">Open-Source Service Discovery</a>》一文中列举了如下开源的服务发现工具。</p><table><thead><tr><th style="text-align:left">Name</th><th style="text-align:left">Type</th><th style="text-align:left">AP or CP</th><th style="text-align:left">Language</th><th style="text-align:left">Dependencies</th><th style="text-align:left">Integration</th></tr></thead><tbody><tr><td style="text-align:left">Zookeeper</td><td style="text-align:left">General</td><td style="text-align:left">CP</td><td style="text-align:left">Java</td><td style="text-align:left">JVM</td><td style="text-align:left">Client Binding</td></tr><tr><td style="text-align:left">Doozer</td><td style="text-align:left">General</td><td style="text-align:left">CP</td><td style="text-align:left">Go</td><td style="text-align:left"></td><td style="text-align:left">Client Binding</td></tr><tr><td style="text-align:left">Etcd</td><td style="text-align:left">General</td><td style="text-align:left">Mixed (1)</td><td style="text-align:left">Go</td><td style="text-align:left"></td><td style="text-align:left">Client Binding/HTTP</td></tr><tr><td style="text-align:left">SmartStack</td><td style="text-align:left">Dedicated</td><td style="text-align:left">AP</td><td style="text-align:left">Ruby</td><td style="text-align:left">haproxy/Zookeeper</td><td style="text-align:left">Sidekick (nerve/synapse)</td></tr><tr><td style="text-align:left">Eureka</td><td style="text-align:left">Dedicated</td><td style="text-align:left">AP</td><td style="text-align:left">Java</td><td style="text-align:left">JVM</td><td style="text-align:left">Java Client</td></tr><tr><td style="text-align:left">NSQ (lookupd)</td><td style="text-align:left">Dedicated</td><td style="text-align:left">AP</td><td style="text-align:left">Go</td><td style="text-align:left"></td><td style="text-align:left">Client Binding</td></tr><tr><td style="text-align:left">Serf</td><td style="text-align:left">Dedicated</td><td style="text-align:left">AP</td><td style="text-align:left">Go</td><td style="text-align:left"></td><td style="text-align:left">Local CLI</td></tr><tr><td style="text-align:left">Spotify (DNS)</td><td style="text-align:left">Dedicated</td><td style="text-align:left">AP</td><td style="text-align:left">N/A</td><td style="text-align:left">Bind</td><td style="text-align:left">DNS Library</td></tr><tr><td style="text-align:left">SkyDNS</td><td style="text-align:left">Dedicated</td><td style="text-align:left">Mixed (2)</td><td style="text-align:left">Go</td><td style="text-align:left"></td><td style="text-align:left">HTTP/DNS Library</td></tr></tbody></table><p>(1) If using the consistent parameter, inconsistent reads are possible<br>(2) If using a caching DNS client in front of SkyDNS, reads could be inconsistent</p><hr><p>上面表格中，前三个是通用的，后面都是各大公司自己造的轮子，应用范围并不广，我也就不深入研究了。<br>此外，这篇文章是14年写的，当时它并没有研究Consul，放到表格中，Consul则应该是General、CP、Go、No dependency、Http/DNS Library。<br>截止到今天，除了容器编排框架k8s、istio/envoy自己实现了服务发现机制（他们也兼容第三方的服务发现工具），似乎也没有其他的知名的服务发现框架出现了。<br>下面我就zookeeper、etcd、consul这三款进行下比较。</p><h2 id="比较"><a href="#比较" class="headerlink" title="比较"></a>比较</h2><h3 id="zookeeper"><a href="#zookeeper" class="headerlink" title="zookeeper"></a>zookeeper</h3><blockquote><p>ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications. Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them ,which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed.</p></blockquote><p>官网这么介绍zookeeper的，翻译过来，zookeeper的功能有：</p><ol><li>作为配置信息的存储的中心服务器</li><li>命名服务</li><li>分布式同步</li><li>分组服务</li></ol><p>能看出，zookeeper并不只是作为服务发现框架使用的，它非常庞大。<br>如果只是打算将zookeeper作为服务发现工具，就需要用到其配置存储和分布式同步的功能。前者可以理解成具有一致性的kv存储，后者提供了zookeeper特有的watcher注册于异步通知机制，zookeeper能将节点的状态实时异步通知给zookeeper客户端。</p><h3 id="zookeeper使用"><a href="#zookeeper使用" class="headerlink" title="zookeeper使用"></a>zookeeper使用</h3><p>zookeeper的使用流程如下：</p><ol><li>确保有所选语言的sdk，理论上github上第三方的库有一些，仔细筛选一下应该可以用。</li><li>调用zookeeper接口连接zookeeper服务器。</li><li>注册自身服务</li><li>通过watcher获取监听服务的状态</li><li>服务提供者需自行保持与zookeeper服务器的心跳。</li></ol><p>《<a href="http://www.cnblogs.com/haippy/archive/2013/02/21/2920280.html" target="_blank" rel="noopener">Zookeeper C API 指南</a>》写了八篇文章介绍了如何使用zookeeper的c语言api。</p><p>总得来说，zookeeper需要胖客户端，每个客户端都需要通过其sdk与zookeeper服务保活，增加了编写程序的复杂性。此外，还提供api实现服务注册与发现逻辑，需要服务的消费者实现服务提供者存活的检测。</p><h3 id="etcd"><a href="#etcd" class="headerlink" title="etcd"></a>etcd</h3><p>etcd是一个采用http协议的分布式键值对存储系统，因其易用，简单。很多系统都采用或支持etcd作为服务发现的一部分，比如kubernetes。但正事因为其只是一个存储系统，如果想要提供完整的服务发现功能，必须搭配一些第三方的工具。<br>比如配合etcd、Registrator、confd组合，就能搭建一个非常简单而强大的服务发现框架。但这种搭建操作就稍微麻烦了点，尤其是相对consul来说。所以etcd大部分场景都是被用来做kv存储，比如kubernetes。</p><h3 id="consul"><a href="#consul" class="headerlink" title="consul"></a>consul</h3><p>相较于etcd、zookeeper，consul最大的特点就是：它整合了用户服务发现普遍的需求，开箱即用，降低了使用的门槛，并不需要任何第三方的工具。代码实现上也足够简单。</p><blockquote><p>Consul has multiple components, but as a whole, it is a tool for discovering and configuring services in your infrastructure. It provides several key features:</p><ol><li>Service Discovery</li><li>Health Checking</li><li>KV Store</li><li>Multi Datacenter</li></ol></blockquote><p>展开了说，consul的功能有：</p><ol><li>通过DNS或HTTP，应用能轻易地找到它们依赖的系统</li><li>提供了多种健康检查方式：http返回码200，内存是否超限，tcp连接是否成功</li><li>kv存储，并提供http api</li><li>多数据中心，这点是zookeeper所不具备的。</li></ol><h3 id="consul使用"><a href="#consul使用" class="headerlink" title="consul使用"></a>consul使用</h3><p>相比于zookeeper的服务发现使用，consul并不需要专门的sdk集成到服务中，因此它不限制任何语言的使用。我们看看consul一般是怎么使用的。</p><ol><li>每台服务器上都要安装一个consul agent。</li><li>consul agent支持通过配置文件注册服务，或者在服务中通过http接口来注册服务。</li><li>注册服务后，consul agent通过指定的健康检查方式，定期检查服务是否存活。</li><li>如果服务想查询其他服务的存活状态，只需要与本机的consul agent发起一次http请求或者dns请求即可。</li></ol><p>简单点说，consul的使用不依赖任何sdk，依靠简单的http请求就能满足服务发现的所有逻辑。<br>不过，服务每次都从consul agent获取其他服务的存活状态，相比于zookeeper的watcher机制，实时性稍差一点，需考虑如何尽可能提高实时性，问题不会很大。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><table><thead><tr><th>名称</th><th>优点</th><th>缺点</th><th>接口</th><th>一致性算法</th></tr></thead><tbody><tr><td>zookeeper</td><td>1.功能强大，不仅仅只是服务发现<br>2.提供watcher机制能实时获取服务提供者的状态<br>3.dubbo等框架支持</td><td>1.没有健康检查<br>2.需在服务中集成sdk，复杂度高<br>3.不支持多数据中心</td><td>sdk</td><td>Paxos</td></tr><tr><td>consul</td><td>1.简单易用，不需要集成sdk<br>2.自带健康检查<br>3.支持多数据中心<br>4.提供web管理界面</td><td>1.不能实时获取服务信息的变化通知</td><td>http/dns</td><td>Raft</td></tr><tr><td>etcd</td><td>1.简单易用，不需要集成sdk<br>2.可配置性强</td><td>1.没有健康检查<br>2.需配合第三方工具一起完成服务发现<br>3.不支持多数据中心</td><td>http</td><td>Raft</td></tr></tbody></table><p>为了以后支持多数据中心，同时为了快速支持不同的语言比如nodejs、python服务，我会选择consul作为我们的服务发现框架，但是实时获取服务信息变化通知的问题需尽可能减小。</p><p><strong>参考文献：</strong><br><a href="https://www.consul.io/intro/vs/index.html" target="_blank" rel="noopener">Consul vs. Other Software</a><br><a href="http://dockone.io/article/667" target="_blank" rel="noopener">服务发现：Zookeeper vs etcd vs Consul</a><br><a href="https://skyao.gitbooks.io/learning-consul/content/introduction/consul_vs_other_software.html" target="_blank" rel="noopener">Consul vs 其他软件</a><br><a href="https://www.slideshare.net/IvanGlushkov/zookeeper-vs-consul-41882991" target="_blank" rel="noopener">Comparing ZooKeeper and Consul</a></p><hr><p>本文链接：<a href="http://www.servercoder.com/2018/03/30/consul-vs-zookeeper-etcd/">http://www.servercoder.com/2018/03/30/consul-vs-zookeeper-etcd/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;本文并不介绍服务发现的基本原理。除了一致性算法之外，其他并没有太多高深的算法，网上的资料很容易让大家明白上面是服务发现。&lt;br&gt;想直接查看结
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>nginx也许并不是service mesh最好的选择，envoy才是</title>
    <link href="http://www.servercoder.com/2018/03/27/envoy-grpc-not-nginx/"/>
    <id>http://www.servercoder.com/2018/03/27/envoy-grpc-not-nginx/</id>
    <published>2018-03-27T12:25:50.665Z</published>
    <updated>2018-03-27T16:27:00.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>前几天好几个公众号推送了这样一篇文章：《Service Mesh利器：NGINX将支持gRPC》，更有甚者鼓吹nginx是第一个支持grpc的代理。看到这几篇文章的时候，我总想说点关于国内的互联网发展。</p><p>这几年国内互联网行业变化飞快。先是微服务，当时国内各大线下交流会议都是各种微服务框架的分享，比如zookeeper采坑之类，微服务的十二要素啊，服务治理什么的。然后接着就是直播行业，这时线下会议又变成了视频秒开啊，如何连麦啊，cdn优化啊等等。不仅技术从业者都往这上面冲，各大投资者也是一个劲地往里砸钱，都不想错过这个风口。到去年，又有人开始鼓吹直播已死。这个时候听到更多的一个词又是devops，这个时候，可能听到的更多就是全链路监控告警，apm优化，devops实践等等。到了今年，情况就更夸张了，kubernetes、区块链、人工智能，尤其是区块链，只要上市公司有一点区块链概念沾边，估价就蹭蹭蹭地网上涨停，比如迅雷、人人网。接下来只怕是公司有一点人工智能的概念，那也会不得了。到今年年末明年年初，我断定，service mesh又肯定会成为各大线下会议的主要课题。</p><p>百花齐放固然是好，但技术的革新不可能如此的快。著名的一万小时理论告诉我们，如果要精通一门技术，一年的时间是远远不够的。我觉得国内互联网氛围有点浮躁了，这不好，尤其是对刚毕业的年轻人。</p><h2 id="什么是grpc"><a href="#什么是grpc" class="headerlink" title="什么是grpc"></a>什么是grpc</h2><blockquote><p>gRPC is a modern open source high performance RPC framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication. It is also applicable in last mile of distributed computing to connect devices, mobile applications and browsers to backend services.</p></blockquote><p>简单点说，grpc就是谷歌出的rpc框架，数据交换格式基于protobuf，数据传输基于http2。谷歌提供了大部分常用语言的sdk。</p><h2 id="grpc代理选择：envoy"><a href="#grpc代理选择：envoy" class="headerlink" title="grpc代理选择：envoy"></a>grpc代理选择：envoy</h2><p>我有幸参与了一个grpc的项目，当时版本还是的0.x。说句题外话，如果是我负责选型，我断不会轻易同意将不稳定的第三方软件应用到产品里，就是非用不可，也一定要深入了解它才行。我踩过太多这样的坑了。</p><p>当时为了做grpc的负载均衡，我特地仔细研究过grpc的官方文档，google的开发人员提到了nghttpx和envoy这两种代理。</p><p>nghttpx是一个基于nghttp2的代理，nghttp2是一个http2的库，前面提到grpc本质是基于http2的通信，所以要想做grpc的代理，必须要底层要能支持http2，这也是为什么最近发布的nginx1.13才支持代理grpc的原因，因为nginx老版本并不支持http2协议。</p><p>要想做好grpc的负载均衡，只是支持http2协议还不够，必须要有基本的负载均衡算法，比如，我们的应用是根据请求的信息，调度到不同的服务器上。要想实现这样的功能，就必须基于python或其他脚本语言配置。</p><p>而envoy在这一方面就强多了，它支持多种负载均衡算法：Round robin、Weighted least request、ring hash、Maglev、Random、Original destination。对于我上面提到的例子，只需要将请求的字段放如grpc的context中，然后配置envoy时根据该字段设置好server的ring hash就行，几句配置就搞定了。</p><p>当然，envoy的强大并不仅仅局限在负载均衡算法多样。它还有如下优点:</p><ol><li>开源，基于Modern C++11</li><li>支持三层、四层、七层代理，支持http路由</li><li>支持服务发现、健康检查。</li><li>支持mongodb、dynamodb</li><li>多种负载均衡算法</li><li>动态配置。nginx并不支持哦。</li></ol><p>这些功能都是开源免费的，但nginx可并不一定，很多进阶功能都需要购买使用nginx plus。</p><p>关于健康检查我多说一句，很多平台的健康检查就是检查某个http接口是否有响应，或是tcp连接是否建立，但这并不代表服务功能正常，这就跟单独开线程做心跳是一个道理，envoy支持数据能正常收发层面的健康检查。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>所以，nginx注定了并不是service mesh的最好选择，因为envoy比它提供了更丰富的功能。不过依然可能会有很多公司使用nginx，因为nginx的运维技术相对成熟，网上资料大把。</p><p>google、ibm公司还基于envoy弄了一套service mesh的框架Istio，有空我再介绍介绍istio。</p><hr><p>本文链接：<a href="http://www.servercoder.com/2018/03/27/envoy-grpc-not-nginx/">http://www.servercoder.com/2018/03/27/envoy-grpc-not-nginx/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;前几天好几个公众号推送了这样一篇文章：《Service Mesh利器：NGINX将支持gRPC》，更有甚者鼓吹nginx是第一个支持grpc
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>基于开源leanote打造多终端同步云笔记应用</title>
    <link href="http://www.servercoder.com/2018/03/11/leanote-private/"/>
    <id>http://www.servercoder.com/2018/03/11/leanote-private/</id>
    <published>2018-03-11T07:47:05.914Z</published>
    <updated>2018-03-11T07:47:05.914Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>写在前面，这并不是一篇leanote的广告。</p></blockquote><p>这些年，我试用过多款云笔记产品，作为一个程序员，我的需求很简单，支持markdown、多终端（windows+mac）同步，界面不要太丑，免费，偶尔导出到pdf。<br>但就是这么简单的需求，似乎很难满足。</p><p>市面上我所知道的云笔记产品有：有道云笔记、Evernote、Quiver、Quip、马克飞象， 当然还有人直接使用markdown编辑器，每次保存时，手动或自动推送到github上。</p><p>下面说说这些软件或多或少让我不太满意的地方：</p><ol><li>EverNote确实是名气最大的笔记软件，但重在收集，一直也不支持markdown。</li><li>有道云笔记在我开始使用的时候，就丑的不能再丑，写这篇文章的时候特地重新使用了一下，交互比几年前清爽多了，也支持mardown，就是免费版带广告，不能导出文档。</li><li>Quiver是我见过的支持的写markdown最舒服，交互最爽的mac版本地笔记软件，就是没有windows版，也不能同步，只能说遗憾了。mac版收费，你知道怎么免费使用的。</li><li>Quip支持多终端，没有使用限制，交互简单，能导出文档，能多终端同步。如果不是因为markdown需求，我是不可能抛弃使用了半年的Quip的</li><li>本地编辑，利用github的public repository做同步，确实够灵活，就是没有了隐私，尤其是设计到机密的文档，一定要慎重。</li></ol><h2 id="leanote功能"><a href="#leanote功能" class="headerlink" title="leanote功能"></a>leanote功能</h2><p>有一天，我突然在开源中国上见到了leanote，当时还没有稳定，只要推广用户就能增加一个月的旗舰会员。使用下来后发现，它竟然满足了我所有的需求：markdown、多终端同步、无限制历史记录、免费、能导出到各种文档。各重要的是，开源！</p><p>后来发现leanote并不支持使用markdown画流程图、时序图等后，一度想换掉，万幸leanote的开发人员集成了这些图表功能，得给他们点个赞。</p><p>当然，leanote也有缺点，我身边很多人不想用的原因也很直接，界面丑！说实在，如果不是实在没有别适合我的软件，我也不太想用leanote的。</p><p>此外，leanote还支持一键发布到博客，对于那些懒得自己搭建博客的同学来说，简直就是太方便了。</p><h2 id="如何免费用leanote"><a href="#如何免费用leanote" class="headerlink" title="如何免费用leanote"></a>如何免费用leanote</h2><p>使用leanote一年多了，现在没有了leanote旗舰会员，如果要想使用旗舰套餐，每年得给leanote贡献150元，说实在，我觉得这个定价有点贵。<br>既然leanote是开源的，正好我手上又有服务器，那就私有化部署咯。</p><p>只要leanote不告我，我承诺3年内不关服，毕竟我自己也要一直使用嘛。blog.servercoder.com，有需要的同学可以自行注册使用。</p><hr><p>本文链接：<a href="http://www.servercoder.com/2018/03/11/leanote-private/">http://www.servercoder.com/2018/03/11/leanote-private/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;blockquote&gt;
&lt;p&gt;写在前面，这并不是一篇leanote的广告。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;这些年，我试用过多款云笔记产品，作为一个程序员，我的需求很简单，支持markdown、多终端（windows+mac）同步，界面不要太丑，免费，偶尔导出到pdf
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>你真的用对protobuf了吗？</title>
    <link href="http://www.servercoder.com/2018/01/10/protobuf-usages/"/>
    <id>http://www.servercoder.com/2018/01/10/protobuf-usages/</id>
    <published>2018-01-10T14:24:54.857Z</published>
    <updated>2018-01-13T15:57:29.893Z</updated>
    
    <content type="html"><![CDATA[<h2 id="历史"><a href="#历史" class="headerlink" title="历史"></a>历史</h2><p>进程间数据交换有很多种方式，比如共享内存、网络通信、文件、数据库等等。如果你的数据并不是整齐有规律，且内存对齐的。大部分情况下，你都需要采用一种数据交换格式来描述你交换的数据，我们通常称之为序列化和反序列化。而描述这些数据的格式，我们通常称之为数据交换格式。</p><p>最原始的数据交换格式就类似于tcp/ip那样的描述，一般称之为二进制数据格式。每一层协议都有包头和包体，包头中会包含包体的长度，数据类型，保留字段dengdeng。当然，不要忘了还有块存储区域保存了数据的校验和。尽管这种格式可读性较差，但这种格式的序列化和反序列化效率是最高的。</p><p>二进制数据格式除了可读性较差以外，扩展性不好是开发者不会普遍采用的主要原因。于是就慢慢发展出了xml和json这两种自描述的数据交换格式。他们可读性强，有确定的schema。起先http的通信大部分基于soap协议，而soap离不开xml。随着前端技术的发展，尤其是javascript对json的支持，使得开发人员能很方便地序列化和反序列化json，于是json慢慢就成了web开发主流的数据交换格式。如今基本很少看到基于xml的接口了，除了部分陈旧的天气预报服务的订阅接口以外。</p><h2 id="为什么选择protobuf"><a href="#为什么选择protobuf" class="headerlink" title="为什么选择protobuf"></a>为什么选择protobuf</h2><p>近几年，又陆续出现了二进制数据交换格式，比如Thrift、Protobuf，还有各大互联网公司自研的号称比protobuf更好的数据交换格式。其中，protobuf封装性更好，与平台语言都无关，使用会更广泛。</p><p>除了rest接约定俗称采用json以外，我们大部分采用protobuf的原因如下：</p><ol><li>速度更快</li><li>空间更小</li><li>浮点数的精度支持不好，尤其是json</li><li>xml、json都是文本型的，如果想存储二进制数据，必须先将其转为文本数据，比如使用base64编码</li><li>安全。json不同语言有各种各样的解析库，代码实现者信息安全经验良莠不齐，大部分库都有远程执行漏洞。而protobuf由谷歌官方维护，能很大程度上保证安全，一旦出现安全隐患也会很快更新。</li></ol><p>大部分人只知道前面两点，并不了解后面三点protobuf的优势。</p><h2 id="protobuf你用对了吗？"><a href="#protobuf你用对了吗？" class="headerlink" title="protobuf你用对了吗？"></a>protobuf你用对了吗？</h2><h3 id="尽量使用proto3"><a href="#尽量使用proto3" class="headerlink" title="尽量使用proto3"></a>尽量使用proto3</h3><p>相比于proto2，proto3更简洁，不需要用户指定required、optional关键字，这点除了开发更方便以外，对于前后兼容也是非常有帮助的，我将在下一条建议中说明。</p><h2 id="版本号"><a href="#版本号" class="headerlink" title="版本号"></a>版本号</h2><p>有很多从json或其他协议转过来的人，还会保留以前那套协议版本号的做法。事实上，这样的做法非常恶心，代码里面会有大量的版本判断和处理。protobuf的设计初衷就是为了避免出现这样恶心的代码的。<br>具体请看<a href="https://developers.google.com/protocol-buffers/docs/overview#a-bit-of-history" target="_blank" rel="noopener">a bit of history</a>、<a href="https://developers.google.com/protocol-buffers/docs/cpptutorial#extending-a-protocol-buffer" target="_blank" rel="noopener">Extending a Protocol Buffer</a></p><p>谷歌是这样讲的:</p><blockquote><p>Protocol buffers were designed to solve many of these problems:</p><p>New fields could be easily introduced, and intermediate servers that didn’t need to inspect the data could simply parse it and pass through the data without needing to know about all the fields.</p><p>Formats were more self-describing, and could be dealt with from a variety of languages (C++, Java, etc.)</p></blockquote><h2 id="存储大量字符串"><a href="#存储大量字符串" class="headerlink" title="存储大量字符串"></a>存储大量字符串</h2><p>有些人会使用protobuf存储大量字符串，更有甚者可能会将json放入protobuf中。<br>如果有心人看过protobuf序列化之后的数据，会发现protobuf对字符串数据是直接拷贝的。所以使用protobuf存储字符串，并没有达到优化空间的目的。</p><h2 id="二进制数据不需要加密"><a href="#二进制数据不需要加密" class="headerlink" title="二进制数据不需要加密"></a>二进制数据不需要加密</h2><p>既然protobuf是二进制数据交换格式，那我们还有必要对其进行加密吗？<br>看过protobuf官方文档的人会知道，protobuf存储思路是这样的：对于不同字段，使用了tag来标识，而基本数据类型，使用了ZigZag类型存储，字符串直接拷贝。<br>换句话说，protobuf就类似与代码混淆一样，将字段名用简化后的字段名表示，只是可读性差一点。但里面所有的值都可以算出来。<br>所以如果安全对你的应用来说很重要的话，还是加密吧。</p><hr><p>本文链接：<a href="http://www.servercoder.com/2018/01/10/protobuf-usages/">http://www.servercoder.com/2018/01/10/protobuf-usages/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;历史&quot;&gt;&lt;a href=&quot;#历史&quot; class=&quot;headerlink&quot; title=&quot;历史&quot;&gt;&lt;/a&gt;历史&lt;/h2&gt;&lt;p&gt;进程间数据交换有很多种方式，比如共享内存、网络通信、文件、数据库等等。如果你的数据并不是整齐有规律，且内存对齐的。大部分情况下，你都需要采用
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>我是怎么处理大小端及网络字节序的？</title>
    <link href="http://www.servercoder.com/2018/01/03/byte-order/"/>
    <id>http://www.servercoder.com/2018/01/03/byte-order/</id>
    <published>2018-01-03T15:00:16.588Z</published>
    <updated>2018-01-10T14:20:39.035Z</updated>
    
    <content type="html"><![CDATA[<h2 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h2><p>最开始接触c语言时，总会花很多精力去记各种操作符的优先级。后来才发现，实际开发根本就不用记。自此这么多年，除了加减乘除这种小学生都知道的优先级，我基本都是用括号搞定优先级。</p><p>同样，不同语言的字节序都不尽相同，比如c++大部分平台是小端存储的（c++的字节序与处理器有关系，具体大小端与编译器对应关系见参考文档1），java就是采用大端存储，c#似乎是小端存储（c#我写的少，有心人可以帮忙确认下）。在写跨语言或者跨平台的程序时，字节序的转换就不得不考虑了。</p><h2 id="大端小端转换"><a href="#大端小端转换" class="headerlink" title="大端小端转换"></a>大端小端转换</h2><p>关于大端小端的由来，可以看看《格列佛游记》，我就不转载了。<br>大端：数据的高位存储在低地址中，低位存储在高地址中。<br>小端：数据的高位存储在高地址中，低位存储在低地址中。</p><p>举个例子，数据0x12345678，占4个字节，分别是0x12、0x34、0x56、0x78。假设内存起始地址是0x80000000。<br>对于小端程序来说，0x80000000存放0x78，0x80000001存放0x56，0x80000002存放0x34，0x80000003存放0x12。<br>而对于大端程序来说，0x80000000存放0x12，0x80000001存放0x34，0x80000002存放0x56，0x80000003存放0x78。</p><p>这里要说明的是，大小端只对多字节数据类型有影响，对于单字节类型的数组、字符串，并没有什么影响。另外如果是多个多字节数据放在一起，顺序依然不会变，只是每个多字节数据区分大端还是小端罢了。</p><p>所以，一般情况下，大小端字节序转换规则如下：</p><ol><li>单字节数据或数组，不需要转换</li><li>少于或等于4字节的长整型，前后互换就行了。</li></ol><p>还有三种特殊情况：</p><ol><li>对于8字节的长整型int64来说，并不是前后字节互换，而是先将高32位和低32位互换，然后，将这两个int32内部字节位互换。</li><li>对于float类型来说，同样是前后字节对换。</li><li>尽管double是8字节的，但是其转换方式和float一样，也是前后字节兑换。</li></ol><p>具体代码可参考poco，我就不贴出来了，参阅参考文献2。</p><h2 id="怎么判断大端还是小端"><a href="#怎么判断大端还是小端" class="headerlink" title="怎么判断大端还是小端"></a>怎么判断大端还是小端</h2><p>可能很多毕业生找工作时都会被问到如何判断当前系统是大端还是小端。知道原理后，实现起来其实很简单。定义一个多字节类型，然后判断不同地址的值，看看高地址存放的是高位数据还是低位数据，就能轻易区分当前是大端还是小端了。</p><p>实际工作中，就没必要这样判断了。因为不同平台上大小端是提前就知道的。如果使用poco库，完成可以依赖其Platform.h中的宏定义，里面还包含了我没有见过的平台。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__ALPHA) || defined(__alpha) || defined(__alpha__) || defined(_M_ALPHA)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_ALPHA</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(i386) || defined(__i386) || defined(__i386__) || defined(_M_IX86) || defined(EMSCRIPTEN) || defined(__EMSCRIPTEN__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_IA32</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(_IA64) || defined(__IA64__) || defined(__ia64__) || defined(__ia64) || defined(_M_IA64)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_IA64</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(hpux) || defined(_hpux)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__x86_64__) || defined(_M_X64)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_AMD64</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__mips__) || defined(__mips) || defined(__MIPS__) || defined(_M_MRX000)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_MIPS</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(POCO_OS_FAMILY_WINDOWS)</span></span><br><span class="line"><span class="comment">// Is this OK? Supports windows only little endian??</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__MIPSEB__) || defined(_MIPSEB) || defined(__MIPSEB)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__MIPSEL__) || defined(_MIPSEL) || defined(__MIPSEL)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">error</span> <span class="meta-string">"MIPS but neither MIPSEL nor MIPSEB?"</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__hppa) || defined(__hppa__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_HPPA</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__PPC) || defined(__POWERPC__) || defined(__powerpc) || defined(__PPC__) || \</span></span><br><span class="line">      defined(__powerpc__) || defined(__ppc__) || defined(__ppc) || defined(_ARCH_PPC) || defined(_M_PPC)</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_PPC</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__BYTE_ORDER__) &amp;&amp; (__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(_POWER) || defined(_ARCH_PWR) || defined(_ARCH_PWR2) || defined(_ARCH_PWR3) || \</span></span><br><span class="line">      defined(_ARCH_PWR4) || defined(__THW_RS6000)</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_POWER</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__sparc__) || defined(__sparc) || defined(sparc)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_SPARC</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__arm__) || defined(__arm) || defined(ARM) || defined(_ARM_) || defined(__ARM__) || defined(_M_ARM)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_ARM</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__ARMEB__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__arm64__) || defined(__arm64)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_ARM64</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__ARMEB__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__BYTE_ORDER__) &amp;&amp; defined(__ORDER_BIG_ENDIAN__) &amp;&amp; __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__m68k__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_M68K</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__s390__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_S390</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__sh__) || defined(__sh) || defined(SHx) || defined(_SHX_)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_SH</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__LITTLE_ENDIAN__) || (POCO_OS == POCO_OS_WINDOWS_CE)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined (nios2) || defined(__nios2) || defined(__nios2__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_NIOS2</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">if</span> defined(__nios2_little_endian) || defined(nios2_little_endian) || defined(__nios2_little_endian__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">else</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__AARCH64EL__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_AARCH64</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_LITTLE_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">elif</span> defined(__AARCH64EB__)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH POCO_ARCH_AARCH64</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> POCO_ARCH_BIG_ENDIAN 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><h2 id="如何将本地字节序转成网络字节序呢？"><a href="#如何将本地字节序转成网络字节序呢？" class="headerlink" title="如何将本地字节序转成网络字节序呢？"></a>如何将本地字节序转成网络字节序呢？</h2><p>本文最开始我提到，如果我们写代码时，不用考虑当前是大端还是小端，就方便极了。<br>poco同样提供了封装：fromNetwork和toNetwork，可以在ByteOrder.h中找到。如果你的项目中没有使用poco，又不想因为大小端问题引入一个库，那问题也不大，无非就是根据大小端情况封装fromNetwork和toNetwork而已，具体实现就直接参考poco的实现就行了。</p><p>参考文档：</p><ol><li><a href="https://github.com/pocoproject/poco/blob/develop/Foundation/include/Poco/Platform.h#L137" target="_blank" rel="noopener">https://github.com/pocoproject/poco/blob/develop/Foundation/include/Poco/Platform.h#L137</a></li><li><a href="https://github.com/pocoproject/poco/blob/develop/Foundation/include/Poco/ByteOrder.h" target="_blank" rel="noopener">https://github.com/pocoproject/poco/blob/develop/Foundation/include/Poco/ByteOrder.h</a></li></ol><hr><p>本文链接：<a href="http://www.servercoder.com/2018/01/03/byte-order/">http://www.servercoder.com/2018/01/03/byte-order/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;背景&quot;&gt;&lt;a href=&quot;#背景&quot; class=&quot;headerlink&quot; title=&quot;背景&quot;&gt;&lt;/a&gt;背景&lt;/h2&gt;&lt;p&gt;最开始接触c语言时，总会花很多精力去记各种操作符的优先级。后来才发现，实际开发根本就不用记。自此这么多年，除了加减乘除这种小学生都知道的优先
      
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>跨平台开发时，我们为什么不封装http请求的sdk</title>
    <link href="http://www.servercoder.com/2017/12/11/sdk-without-http/"/>
    <id>http://www.servercoder.com/2017/12/11/sdk-without-http/</id>
    <published>2017-12-11T11:09:42.985Z</published>
    <updated>2017-12-11T11:09:42.985Z</updated>
    
    <content type="html"><![CDATA[<h2 id="为什么要封装sdk"><a href="#为什么要封装sdk" class="headerlink" title="为什么要封装sdk"></a>为什么要封装sdk</h2><p>相信很多开发团队都同时需要开发各种平台的客户端，有android、ios，甚至是pc版客户端。于是，怎么尽可能复用同一套业务代码，成了很多开发讨论的话题。</p><p>比如，开发照片处理软件，核心的处理算法一定都是c++写的，除了计算效率高之外，算法的实现也肯定是很复杂的，不可能每个客户端都用各自编程语言实现一套。这样带来的好处有：</p><ol><li>代码量更少，开发效率高。</li><li>减少了不同语言实现时产生相同bug的可能。</li><li>减少了因不同语言开发人员开发水平不一致，出现各种bug的可能。</li><li>后期维护更方便。</li><li>测试更方便。</li></ol><p>同样地，当你引入一个新的通信库时，如grpc。它提供了不同语言的实现，java、go、c++。如果每个语言都基于grpc封装一套通信逻辑，意味着每个语言的人都要了解grpc的使用，如果要求高一点，我们对引入的第三方库一定要读懂核心代码，那耗费的时间就更多了。更别说后期维护的时间。</p><h2 id="什么时候要封装sdk"><a href="#什么时候要封装sdk" class="headerlink" title="什么时候要封装sdk"></a>什么时候要封装sdk</h2><p>所以，我们到底什么时候该封装sdk呢？我认为出现下面几种情况，你可能就得考虑封装sdk了。</p><ol><li>业务逻辑复杂，并且多平台客户端都需要。</li><li>复杂的算法。</li><li>网络通信中间件。比如我上面提到的grpc,还有一些基于tcp数据的封装、发送、解析。</li><li>多个项目可能会使用的公共模块。</li></ol><h2 id="http请求，是否要封装？"><a href="#http请求，是否要封装？" class="headerlink" title="http请求，是否要封装？"></a>http请求，是否要封装？</h2><p>我们常说的一句话，架构设计不能脱离业务。诚然，我们很多时候的技术选型都是在权衡，权衡开发成本，权衡产品状态，权衡现有开发人员的水平等等。有的时候具体问题还是要具体分析。<br>上面说了那么多什么时候要封装sdk。那对于提供http接口的服务，有必要封装sdk吗？<br>我认为如果只是封装http的请求和响应，而不包含其他业务逻辑时，必要性不大，原因如下：</p><ol><li>如果将http的请求和相应封装成sdk，我们看看是否提高了开发效率。首先确实只有一处公共代码发起http请求和响应，但为此，需要为各个客户端封装接口，以便能调用sdk。比如，c#需要封装托管c++或是提供c语言形式地接口，然后c#在以invoke的方式调用。比如，java和andriod，我们需要封装jni接口。其他语言就更别说了，能间接调用c接口，但都要简单的封装。于是，后期我们每增加一个接口都需要修改sdk，需要修改调用接口。这样做提高效率了吗？有人可能会说，sdk中发起http请求和相应的代码复用了，我减少了开发和维护成本呢。</li><li>但不要忘记了，各个语言都有非常成熟且经过充分验证的http client api。也就是说，各个高级开发语言（除了c++）不需要额外的开发精力，我们就能实现稳定的http调用。</li><li>对于http服务来说，如果设计人员的水平还行的话，我们不可能需要频繁修改接口，更多的是新增接口。而对于新增接口而言，我们并没有节省什么开发成本。</li><li>你能保证你封装的接口一次性交付么？</li></ol><h2 id="封装sdk可能带来的问题"><a href="#封装sdk可能带来的问题" class="headerlink" title="封装sdk可能带来的问题"></a>封装sdk可能带来的问题</h2><p>再说远一点，并不是说为了增加复用，提高开发效率就一定要封装sdk。如果是服务端开发人员，如果多个项目都包含同一份sdk，一旦该sdk出了问题，就意味着所有相关项目都需要重新升级部署。<br>这个时候就该考虑服务化了，如果该sdk相关逻辑在一个单独的服务里面，我们只需要更新该服务就行，这样相关项目与那段逻辑就实现了解耦。沈剑的这篇文章<a href="https://mp.weixin.qq.com/s/mjWCuYYbFs16esvkwZ-LKw" target="_blank" rel="noopener">《小小的公共库，大大的耦合，你痛过吗？》</a>，大家可以关注下。</p><hr><p>本文链接：<a href="http://www.servercoder.com/2017/12/11/sdk-without-http/">http://www.servercoder.com/2017/12/11/sdk-without-http/</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;为什么要封装sdk&quot;&gt;&lt;a href=&quot;#为什么要封装sdk&quot; class=&quot;headerlink&quot; title=&quot;为什么要封装sdk&quot;&gt;&lt;/a&gt;为什么要封装sdk&lt;/h2&gt;&lt;p&gt;相信很多开发团队都同时需要开发各种平台的客户端，有android、ios，甚至是pc
      
    
    </summary>
    
    
  </entry>
  
</feed>
