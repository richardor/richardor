<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[服务发现框架选型，Consul还是Zookeeper还是etcd]]></title>
    <url>%2F2018%2F03%2F30%2Fconsul-vs-zookeeper-etcd%2F</url>
    <content type="text"><![CDATA[背景本文并不介绍服务发现的基本原理。除了一致性算法之外，其他并没有太多高深的算法，网上的资料很容易让大家明白上面是服务发现。想直接查看结论的同学，请直接跳到文末。目前，市面上有非常多的服务发现工具，《Open-Source Service Discovery》一文中列举了如下开源的服务发现工具。|Name| Type| AP or CP| Language| Dependencies| Integration||:—|:—|:—|:—|:—|:—||Zookeeper| General |CP| Java| JVM |Client Binding||Doozer| General |CP| Go| |Client Binding||Etcd| General| Mixed (1) |Go|| Client Binding/HTTP||SmartStack| Dedicated| AP| Ruby| haproxy/Zookeeper| Sidekick (nerve/synapse)||Eureka| Dedicated| AP| Java| JVM| Java Client||NSQ (lookupd) |Dedicated| AP| Go| | Client Binding||Serf| Dedicated| AP| Go| |Local CLI||Spotify (DNS) |Dedicated| AP| N/A| Bind| DNS Library||SkyDNS| Dedicated| Mixed (2) |Go|| HTTP/DNS Library| (1) If using the consistent parameter, inconsistent reads are possible(2) If using a caching DNS client in front of SkyDNS, reads could be inconsistent 上面表格中，前三个是通用的，后面都是各大公司自己造的轮子，应用范围并不广，我也就不深入研究了。此外，这篇文章是14年写的，当时它并没有研究Consul，放到表格中，Consul则应该是General、CP、Go、No dependency、Http/DNS Library。截止到今天，除了容器编排框架k8s、istio/envoy自己实现了服务发现机制（他们也兼容第三方的服务发现工具），似乎也没有其他的知名的服务发现框架出现了。下面我就zookeeper、etcd、consul这三款进行下比较。 比较zookeeper ZooKeeper is a centralized service for maintaining configuration information, naming, providing distributed synchronization, and providing group services. All of these kinds of services are used in some form or another by distributed applications. Each time they are implemented there is a lot of work that goes into fixing the bugs and race conditions that are inevitable. Because of the difficulty of implementing these kinds of services, applications initially usually skimp on them ,which make them brittle in the presence of change and difficult to manage. Even when done correctly, different implementations of these services lead to management complexity when the applications are deployed. 官网这么介绍zookeeper的，翻译过来，zookeeper的功能有： 作为配置信息的存储的中心服务器 命名服务 分布式同步 分组服务 能看出，zookeeper并不只是作为服务发现框架使用的，它非常庞大。如果只是打算将zookeeper作为服务发现工具，就需要用到其配置存储和分布式同步的功能。前者可以理解成具有一致性的kv存储，后者提供了zookeeper特有的watcher注册于异步通知机制，zookeeper能将节点的状态实时异步通知给zookeeper客户端。 zookeeper使用zookeeper的使用流程如下： 确保有所选语言的sdk，理论上github上第三方的库有一些，仔细筛选一下应该可以用。 调用zookeeper接口连接zookeeper服务器。 注册自身服务 通过watcher获取监听服务的状态 服务提供者需自行保持与zookeeper服务器的心跳。 《Zookeeper C API 指南》写了八篇文章介绍了如何使用zookeeper的c语言api。 总得来说，zookeeper需要胖客户端，每个客户端都需要通过其sdk与zookeeper服务保活，增加了编写程序的复杂性。此外，还提供api实现服务注册与发现逻辑，需要服务的消费者实现服务提供者存活的检测。 etcdetcd是一个采用http协议的分布式键值对存储系统，因其易用，简单。很多系统都采用或支持etcd作为服务发现的一部分，比如kubernetes。但正事因为其只是一个存储系统，如果想要提供完整的服务发现功能，必须搭配一些第三方的工具。比如配合etcd、Registrator、confd组合，就能搭建一个非常简单而强大的服务发现框架。但这种搭建操作就稍微麻烦了点，尤其是相对consul来说。所以etcd大部分场景都是被用来做kv存储，比如kubernetes。 consul相较于etcd、zookeeper，consul最大的特点就是：它整合了用户服务发现普遍的需求，开箱即用，降低了使用的门槛，并不需要任何第三方的工具。代码实现上也足够简单。 Consul has multiple components, but as a whole, it is a tool for discovering and configuring services in your infrastructure. It provides several key features: Service Discovery Health Checking KV Store Multi Datacenter 展开了说，consul的功能有： 通过DNS或HTTP，应用能轻易地找到它们依赖的系统 提供了多种健康检查方式：http返回码200，内存是否超限，tcp连接是否成功 kv存储，并提供http api 多数据中心，这点是zookeeper所不具备的。 consul使用相比于zookeeper的服务发现使用，consul并不需要专门的sdk集成到服务中，因此它不限制任何语言的使用。我们看看consul一般是怎么使用的。 每台服务器上都要安装一个consul agent。 consul agent支持通过配置文件注册服务，或者在服务中通过http接口来注册服务。 注册服务后，consul agent通过指定的健康检查方式，定期检查服务是否存活。 如果服务想查询其他服务的存活状态，只需要与本机的consul agent发起一次http请求或者dns请求即可。 简单点说，consul的使用不依赖任何sdk，依靠简单的http请求就能满足服务发现的所有逻辑。不过，服务每次都从consul agent获取其他服务的存活状态，相比于zookeeper的watcher机制，实时性稍差一点，需考虑如何尽可能提高实时性，问题不会很大。 总结 名称 优点 缺点 接口 一致性算法 zookeeper 1.功能强大，不仅仅只是服务发现2.提供watcher机制能实时获取服务提供者的状态3.dubbo等框架支持 1.没有健康检查2.需在服务中集成sdk，复杂度高3.不支持多数据中心 sdk Paxos consul 1.简单易用，不需要集成sdk2.自带健康检查3.支持多数据中心4.提供web管理界面 1.不能实时获取服务信息的变化通知 http/dns Raft etcd 1.简单易用，不需要集成sdk2.可配置性强 1.没有健康检查2.需配合第三方工具一起完成服务发现3.不支持多数据中心 http Raft 为了以后支持多数据中心，同时为了快速支持不同的语言比如nodejs、python服务，我会选择consul作为我们的服务发现框架，但是实时获取服务信息变化通知的问题需尽可能减小。 参考文献：Consul vs. Other Software服务发现：Zookeeper vs etcd vs ConsulConsul vs 其他软件Comparing ZooKeeper and Consul 本文链接：http://www.servercoder.com/2018/03/30/consul-vs-zookeeper-etcd/]]></content>
  </entry>
  <entry>
    <title><![CDATA[nginx也许并不是service mesh最好的选择，envoy才是]]></title>
    <url>%2F2018%2F03%2F27%2Fenvoy-grpc-not-nginx%2F</url>
    <content type="text"><![CDATA[背景前几天好几个公众号推送了这样一篇文章：《Service Mesh利器：NGINX将支持gRPC》，更有甚者鼓吹nginx是第一个支持grpc的代理。看到这几篇文章的时候，我总想说点关于国内的互联网发展。 这几年国内互联网行业变化飞快。先是微服务，当时国内各大线下交流会议都是各种微服务框架的分享，比如zookeeper采坑之类，微服务的十二要素啊，服务治理什么的。然后接着就是直播行业，这时线下会议又变成了视频秒开啊，如何连麦啊，cdn优化啊等等。不仅技术从业者都往这上面冲，各大投资者也是一个劲地往里砸钱，都不想错过这个风口。到去年，又有人开始鼓吹直播已死。这个时候听到更多的一个词又是devops，这个时候，可能听到的更多就是全链路监控告警，apm优化，devops实践等等。到了今年，情况就更夸张了，kubernetes、区块链、人工智能，尤其是区块链，只要上市公司有一点区块链概念沾边，估价就蹭蹭蹭地网上涨停，比如迅雷、人人网。接下来只怕是公司有一点人工智能的概念，那也会不得了。到今年年末明年年初，我断定，service mesh又肯定会成为各大线下会议的主要课题。 百花齐放固然是好，但技术的革新不可能如此的快。著名的一万小时理论告诉我们，如果要精通一门技术，一年的时间是远远不够的。我觉得国内互联网氛围有点浮躁了，这不好，尤其是对刚毕业的年轻人。 什么是grpc gRPC is a modern open source high performance RPC framework that can run in any environment. It can efficiently connect services in and across data centers with pluggable support for load balancing, tracing, health checking and authentication. It is also applicable in last mile of distributed computing to connect devices, mobile applications and browsers to backend services. 简单点说，grpc就是谷歌出的rpc框架，数据交换格式基于protobuf，数据传输基于http2。谷歌提供了大部分常用语言的sdk。 grpc代理选择：envoy我有幸参与了一个grpc的项目，当时版本还是的0.x。说句题外话，如果是我负责选型，我断不会轻易同意将不稳定的第三方软件应用到产品里，就是非用不可，也一定要深入了解它才行。我踩过太多这样的坑了。 当时为了做grpc的负载均衡，我特地仔细研究过grpc的官方文档，google的开发人员提到了nghttpx和envoy这两种代理。 nghttpx是一个基于nghttp2的代理，nghttp2是一个http2的库，前面提到grpc本质是基于http2的通信，所以要想做grpc的代理，必须要底层要能支持http2，这也是为什么最近发布的nginx1.13才支持代理grpc的原因，因为nginx老版本并不支持http2协议。 要想做好grpc的负载均衡，只是支持http2协议还不够，必须要有基本的负载均衡算法，比如，我们的应用是根据请求的信息，调度到不同的服务器上。要想实现这样的功能，就必须基于python或其他脚本语言配置。 而envoy在这一方面就强多了，它支持多种负载均衡算法：Round robin、Weighted least request、ring hash、Maglev、Random、Original destination。对于我上面提到的例子，只需要将请求的字段放如grpc的context中，然后配置envoy时根据该字段设置好server的ring hash就行，几句配置就搞定了。 当然，envoy的强大并不仅仅局限在负载均衡算法多样。它还有如下优点: 开源，基于Modern C++11 支持三层、四层、七层代理，支持http路由 支持服务发现、健康检查。 支持mongodb、dynamodb 多种负载均衡算法 动态配置。nginx并不支持哦。 这些功能都是开源免费的，但nginx可并不一定，很多进阶功能都需要购买使用nginx plus。 关于健康检查我多说一句，很多平台的健康检查就是检查某个http接口是否有响应，或是tcp连接是否建立，但这并不代表服务功能正常，这就跟单独开线程做心跳是一个道理，envoy支持数据能正常收发层面的健康检查。 总结所以，nginx注定了并不是service mesh的最好选择，因为envoy比它提供了更丰富的功能。不过依然可能会有很多公司使用nginx，因为nginx的运维技术相对成熟，网上资料大把。 google、ibm公司还基于envoy弄了一套service mesh的框架Istio，有空我再介绍介绍istio。 本文链接：http://www.servercoder.com/2018/03/27/envoy-grpc-not-nginx/]]></content>
  </entry>
  <entry>
    <title><![CDATA[基于开源leanote打造多终端同步云笔记应用]]></title>
    <url>%2F2018%2F03%2F11%2Fleanote-private%2F</url>
    <content type="text"><![CDATA[写在前面，这并不是一篇leanote的广告。 这些年，我试用过多款云笔记产品，作为一个程序员，我的需求很简单，支持markdown、多终端（windows+mac）同步，界面不要太丑，免费，偶尔导出到pdf。但就是这么简单的需求，似乎很难满足。 市面上我所知道的云笔记产品有：有道云笔记、Evernote、Quiver、Quip、马克飞象， 当然还有人直接使用markdown编辑器，每次保存时，手动或自动推送到github上。 下面说说这些软件或多或少让我不太满意的地方： EverNote确实是名气最大的笔记软件，但重在收集，一直也不支持markdown。 有道云笔记在我开始使用的时候，就丑的不能再丑，写这篇文章的时候特地重新使用了一下，交互比几年前清爽多了，也支持mardown，就是免费版带广告，不能导出文档。 Quiver是我见过的支持的写markdown最舒服，交互最爽的mac版本地笔记软件，就是没有windows版，也不能同步，只能说遗憾了。mac版收费，你知道怎么免费使用的。 Quip支持多终端，没有使用限制，交互简单，能导出文档，能多终端同步。如果不是因为markdown需求，我是不可能抛弃使用了半年的Quip的 本地编辑，利用github的public repository做同步，确实够灵活，就是没有了隐私，尤其是设计到机密的文档，一定要慎重。 leanote功能有一天，我突然在开源中国上见到了leanote，当时还没有稳定，只要推广用户就能增加一个月的旗舰会员。使用下来后发现，它竟然满足了我所有的需求：markdown、多终端同步、无限制历史记录、免费、能导出到各种文档。各重要的是，开源！ 后来发现leanote并不支持使用markdown画流程图、时序图等后，一度想换掉，万幸leanote的开发人员集成了这些图表功能，得给他们点个赞。 当然，leanote也有缺点，我身边很多人不想用的原因也很直接，界面丑！说实在，如果不是实在没有别适合我的软件，我也不太想用leanote的。 此外，leanote还支持一键发布到博客，对于那些懒得自己搭建博客的同学来说，简直就是太方便了。 如何免费用leanote使用leanote一年多了，现在没有了leanote旗舰会员，如果要想使用旗舰套餐，每年得给leanote贡献150元，说实在，我觉得这个定价有点贵。既然leanote是开源的，正好我手上又有服务器，那就私有化部署咯。 只要leanote不告我，我承诺3年内不关服，毕竟我自己也要一直使用嘛。blog.servercoder.com，有需要的同学可以自行注册使用。 本文链接：http://www.servercoder.com/2018/03/11/leanote-private/]]></content>
  </entry>
  <entry>
    <title><![CDATA[你真的用对protobuf了吗？]]></title>
    <url>%2F2018%2F01%2F10%2Fprotobuf-usages%2F</url>
    <content type="text"><![CDATA[历史进程间数据交换有很多种方式，比如共享内存、网络通信、文件、数据库等等。如果你的数据并不是整齐有规律，且内存对齐的。大部分情况下，你都需要采用一种数据交换格式来描述你交换的数据，我们通常称之为序列化和反序列化。而描述这些数据的格式，我们通常称之为数据交换格式。 最原始的数据交换格式就类似于tcp/ip那样的描述，一般称之为二进制数据格式。每一层协议都有包头和包体，包头中会包含包体的长度，数据类型，保留字段dengdeng。当然，不要忘了还有块存储区域保存了数据的校验和。尽管这种格式可读性较差，但这种格式的序列化和反序列化效率是最高的。 二进制数据格式除了可读性较差以外，扩展性不好是开发者不会普遍采用的主要原因。于是就慢慢发展出了xml和json这两种自描述的数据交换格式。他们可读性强，有确定的schema。起先http的通信大部分基于soap协议，而soap离不开xml。随着前端技术的发展，尤其是javascript对json的支持，使得开发人员能很方便地序列化和反序列化json，于是json慢慢就成了web开发主流的数据交换格式。如今基本很少看到基于xml的接口了，除了部分陈旧的天气预报服务的订阅接口以外。 为什么选择protobuf近几年，又陆续出现了二进制数据交换格式，比如Thrift、Protobuf，还有各大互联网公司自研的号称比protobuf更好的数据交换格式。其中，protobuf封装性更好，与平台语言都无关，使用会更广泛。 除了rest接约定俗称采用json以外，我们大部分采用protobuf的原因如下： 速度更快 空间更小 浮点数的精度支持不好，尤其是json xml、json都是文本型的，如果想存储二进制数据，必须先将其转为文本数据，比如使用base64编码 安全。json不同语言有各种各样的解析库，代码实现者信息安全经验良莠不齐，大部分库都有远程执行漏洞。而protobuf由谷歌官方维护，能很大程度上保证安全，一旦出现安全隐患也会很快更新。 大部分人只知道前面两点，并不了解后面三点protobuf的优势。 protobuf你用对了吗？尽量使用proto3相比于proto2，proto3更简洁，不需要用户指定required、optional关键字，这点除了开发更方便以外，对于前后兼容也是非常有帮助的，我将在下一条建议中说明。 版本号有很多从json或其他协议转过来的人，还会保留以前那套协议版本号的做法。事实上，这样的做法非常恶心，代码里面会有大量的版本判断和处理。protobuf的设计初衷就是为了避免出现这样恶心的代码的。具体请看a bit of history、Extending a Protocol Buffer 谷歌是这样讲的: Protocol buffers were designed to solve many of these problems: New fields could be easily introduced, and intermediate servers that didn’t need to inspect the data could simply parse it and pass through the data without needing to know about all the fields. Formats were more self-describing, and could be dealt with from a variety of languages (C++, Java, etc.) 存储大量字符串有些人会使用protobuf存储大量字符串，更有甚者可能会将json放入protobuf中。如果有心人看过protobuf序列化之后的数据，会发现protobuf对字符串数据是直接拷贝的。所以使用protobuf存储字符串，并没有达到优化空间的目的。 二进制数据不需要加密既然protobuf是二进制数据交换格式，那我们还有必要对其进行加密吗？看过protobuf官方文档的人会知道，protobuf存储思路是这样的：对于不同字段，使用了tag来标识，而基本数据类型，使用了ZigZag类型存储，字符串直接拷贝。换句话说，protobuf就类似与代码混淆一样，将字段名用简化后的字段名表示，只是可读性差一点。但里面所有的值都可以算出来。所以如果安全对你的应用来说很重要的话，还是加密吧。 本文链接：http://www.servercoder.com/2018/01/10/protobuf-usages/]]></content>
  </entry>
  <entry>
    <title><![CDATA[我是怎么处理大小端及网络字节序的？]]></title>
    <url>%2F2018%2F01%2F03%2Fbyte-order%2F</url>
    <content type="text"><![CDATA[背景最开始接触c语言时，总会花很多精力去记各种操作符的优先级。后来才发现，实际开发根本就不用记。自此这么多年，除了加减乘除这种小学生都知道的优先级，我基本都是用括号搞定优先级。 同样，不同语言的字节序都不尽相同，比如c++大部分平台是小端存储的（c++的字节序与处理器有关系，具体大小端与编译器对应关系见参考文档1），java就是采用大端存储，c#似乎是小端存储（c#我写的少，有心人可以帮忙确认下）。在写跨语言或者跨平台的程序时，字节序的转换就不得不考虑了。 大端小端转换关于大端小端的由来，可以看看《格列佛游记》，我就不转载了。大端：数据的高位存储在低地址中，低位存储在高地址中。小端：数据的高位存储在高地址中，低位存储在低地址中。 举个例子，数据0x12345678，占4个字节，分别是0x12、0x34、0x56、0x78。假设内存起始地址是0x80000000。对于小端程序来说，0x80000000存放0x78，0x80000001存放0x56，0x80000002存放0x34，0x80000003存放0x12。而对于大端程序来说，0x80000000存放0x12，0x80000001存放0x34，0x80000002存放0x56，0x80000003存放0x78。 这里要说明的是，大小端只对多字节数据类型有影响，对于单字节类型的数组、字符串，并没有什么影响。另外如果是多个多字节数据放在一起，顺序依然不会变，只是每个多字节数据区分大端还是小端罢了。 所以，一般情况下，大小端字节序转换规则如下： 单字节数据或数组，不需要转换 少于或等于4字节的长整型，前后互换就行了。 还有三种特殊情况： 对于8字节的长整型int64来说，并不是前后字节互换，而是先将高32位和低32位互换，然后，将这两个int32内部字节位互换。 对于float类型来说，同样是前后字节对换。 尽管double是8字节的，但是其转换方式和float一样，也是前后字节兑换。 具体代码可参考poco，我就不贴出来了，参阅参考文献2。 怎么判断大端还是小端可能很多毕业生找工作时都会被问到如何判断当前系统是大端还是小端。知道原理后，实现起来其实很简单。定义一个多字节类型，然后判断不同地址的值，看看高地址存放的是高位数据还是低位数据，就能轻易区分当前是大端还是小端了。 实际工作中，就没必要这样判断了。因为不同平台上大小端是提前就知道的。如果使用poco库，完成可以依赖其Platform.h中的宏定义，里面还包含了我没有见过的平台。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#if defined(__ALPHA) || defined(__alpha) || defined(__alpha__) || defined(_M_ALPHA) #define POCO_ARCH POCO_ARCH_ALPHA #define POCO_ARCH_LITTLE_ENDIAN 1#elif defined(i386) || defined(__i386) || defined(__i386__) || defined(_M_IX86) || defined(EMSCRIPTEN) || defined(__EMSCRIPTEN__) #define POCO_ARCH POCO_ARCH_IA32 #define POCO_ARCH_LITTLE_ENDIAN 1#elif defined(_IA64) || defined(__IA64__) || defined(__ia64__) || defined(__ia64) || defined(_M_IA64) #define POCO_ARCH POCO_ARCH_IA64 #if defined(hpux) || defined(_hpux) #define POCO_ARCH_BIG_ENDIAN 1 #else #define POCO_ARCH_LITTLE_ENDIAN 1 #endif#elif defined(__x86_64__) || defined(_M_X64) #define POCO_ARCH POCO_ARCH_AMD64 #define POCO_ARCH_LITTLE_ENDIAN 1#elif defined(__mips__) || defined(__mips) || defined(__MIPS__) || defined(_M_MRX000) #define POCO_ARCH POCO_ARCH_MIPS #if defined(POCO_OS_FAMILY_WINDOWS) // Is this OK? Supports windows only little endian?? #define POCO_ARCH_LITTLE_ENDIAN 1 #elif defined(__MIPSEB__) || defined(_MIPSEB) || defined(__MIPSEB) #define POCO_ARCH_BIG_ENDIAN 1 #elif defined(__MIPSEL__) || defined(_MIPSEL) || defined(__MIPSEL) #define POCO_ARCH_LITTLE_ENDIAN 1 #else #error "MIPS but neither MIPSEL nor MIPSEB?" #endif#elif defined(__hppa) || defined(__hppa__) #define POCO_ARCH POCO_ARCH_HPPA #define POCO_ARCH_BIG_ENDIAN 1#elif defined(__PPC) || defined(__POWERPC__) || defined(__powerpc) || defined(__PPC__) || \ defined(__powerpc__) || defined(__ppc__) || defined(__ppc) || defined(_ARCH_PPC) || defined(_M_PPC) #define POCO_ARCH POCO_ARCH_PPC #if defined(__BYTE_ORDER__) &amp;&amp; (__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__) #define POCO_ARCH_LITTLE_ENDIAN 1 #else #define POCO_ARCH_BIG_ENDIAN 1 #endif#elif defined(_POWER) || defined(_ARCH_PWR) || defined(_ARCH_PWR2) || defined(_ARCH_PWR3) || \ defined(_ARCH_PWR4) || defined(__THW_RS6000) #define POCO_ARCH POCO_ARCH_POWER #define POCO_ARCH_BIG_ENDIAN 1#elif defined(__sparc__) || defined(__sparc) || defined(sparc) #define POCO_ARCH POCO_ARCH_SPARC #define POCO_ARCH_BIG_ENDIAN 1#elif defined(__arm__) || defined(__arm) || defined(ARM) || defined(_ARM_) || defined(__ARM__) || defined(_M_ARM) #define POCO_ARCH POCO_ARCH_ARM #if defined(__ARMEB__) #define POCO_ARCH_BIG_ENDIAN 1 #else #define POCO_ARCH_LITTLE_ENDIAN 1 #endif#elif defined(__arm64__) || defined(__arm64) #define POCO_ARCH POCO_ARCH_ARM64 #if defined(__ARMEB__) #define POCO_ARCH_BIG_ENDIAN 1 #elif defined(__BYTE_ORDER__) &amp;&amp; defined(__ORDER_BIG_ENDIAN__) &amp;&amp; __BYTE_ORDER__ == __ORDER_BIG_ENDIAN__ #define POCO_ARCH_BIG_ENDIAN 1 #else #define POCO_ARCH_LITTLE_ENDIAN 1 #endif#elif defined(__m68k__) #define POCO_ARCH POCO_ARCH_M68K #define POCO_ARCH_BIG_ENDIAN 1#elif defined(__s390__) #define POCO_ARCH POCO_ARCH_S390 #define POCO_ARCH_BIG_ENDIAN 1#elif defined(__sh__) || defined(__sh) || defined(SHx) || defined(_SHX_) #define POCO_ARCH POCO_ARCH_SH #if defined(__LITTLE_ENDIAN__) || (POCO_OS == POCO_OS_WINDOWS_CE) #define POCO_ARCH_LITTLE_ENDIAN 1 #else #define POCO_ARCH_BIG_ENDIAN 1 #endif#elif defined (nios2) || defined(__nios2) || defined(__nios2__) #define POCO_ARCH POCO_ARCH_NIOS2 #if defined(__nios2_little_endian) || defined(nios2_little_endian) || defined(__nios2_little_endian__) #define POCO_ARCH_LITTLE_ENDIAN 1 #else #define POCO_ARCH_BIG_ENDIAN 1 #endif#elif defined(__AARCH64EL__) #define POCO_ARCH POCO_ARCH_AARCH64 #define POCO_ARCH_LITTLE_ENDIAN 1#elif defined(__AARCH64EB__) #define POCO_ARCH POCO_ARCH_AARCH64 #define POCO_ARCH_BIG_ENDIAN 1#endif 如何将本地字节序转成网络字节序呢？本文最开始我提到，如果我们写代码时，不用考虑当前是大端还是小端，就方便极了。poco同样提供了封装：fromNetwork和toNetwork，可以在ByteOrder.h中找到。如果你的项目中没有使用poco，又不想因为大小端问题引入一个库，那问题也不大，无非就是根据大小端情况封装fromNetwork和toNetwork而已，具体实现就直接参考poco的实现就行了。 参考文档： https://github.com/pocoproject/poco/blob/develop/Foundation/include/Poco/Platform.h#L137 https://github.com/pocoproject/poco/blob/develop/Foundation/include/Poco/ByteOrder.h 本文链接：http://www.servercoder.com/2018/01/03/byte-order/]]></content>
  </entry>
  <entry>
    <title><![CDATA[跨平台开发时，我们为什么不封装http请求的sdk]]></title>
    <url>%2F2017%2F12%2F11%2Fsdk-without-http%2F</url>
    <content type="text"><![CDATA[为什么要封装sdk相信很多开发团队都同时需要开发各种平台的客户端，有android、ios，甚至是pc版客户端。于是，怎么尽可能复用同一套业务代码，成了很多开发讨论的话题。 比如，开发照片处理软件，核心的处理算法一定都是c++写的，除了计算效率高之外，算法的实现也肯定是很复杂的，不可能每个客户端都用各自编程语言实现一套。这样带来的好处有： 代码量更少，开发效率高。 减少了不同语言实现时产生相同bug的可能。 减少了因不同语言开发人员开发水平不一致，出现各种bug的可能。 后期维护更方便。 测试更方便。 同样地，当你引入一个新的通信库时，如grpc。它提供了不同语言的实现，java、go、c++。如果每个语言都基于grpc封装一套通信逻辑，意味着每个语言的人都要了解grpc的使用，如果要求高一点，我们对引入的第三方库一定要读懂核心代码，那耗费的时间就更多了。更别说后期维护的时间。 什么时候要封装sdk所以，我们到底什么时候该封装sdk呢？我认为出现下面几种情况，你可能就得考虑封装sdk了。 业务逻辑复杂，并且多平台客户端都需要。 复杂的算法。 网络通信中间件。比如我上面提到的grpc,还有一些基于tcp数据的封装、发送、解析。 多个项目可能会使用的公共模块。 http请求，是否要封装？我们常说的一句话，架构设计不能脱离业务。诚然，我们很多时候的技术选型都是在权衡，权衡开发成本，权衡产品状态，权衡现有开发人员的水平等等。有的时候具体问题还是要具体分析。上面说了那么多什么时候要封装sdk。那对于提供http接口的服务，有必要封装sdk吗？我认为如果只是封装http的请求和响应，而不包含其他业务逻辑时，必要性不大，原因如下： 如果将http的请求和相应封装成sdk，我们看看是否提高了开发效率。首先确实只有一处公共代码发起http请求和响应，但为此，需要为各个客户端封装接口，以便能调用sdk。比如，c#需要封装托管c++或是提供c语言形式地接口，然后c#在以invoke的方式调用。比如，java和andriod，我们需要封装jni接口。其他语言就更别说了，能间接调用c接口，但都要简单的封装。于是，后期我们每增加一个接口都需要修改sdk，需要修改调用接口。这样做提高效率了吗？有人可能会说，sdk中发起http请求和相应的代码复用了，我减少了开发和维护成本呢。 但不要忘记了，各个语言都有非常成熟且经过充分验证的http client api。也就是说，各个高级开发语言（除了c++）不需要额外的开发精力，我们就能实现稳定的http调用。 对于http服务来说，如果设计人员的水平还行的话，我们不可能需要频繁修改接口，更多的是新增接口。而对于新增接口而言，我们并没有节省什么开发成本。 你能保证你封装的接口一次性交付么？ 封装sdk可能带来的问题再说远一点，并不是说为了增加复用，提高开发效率就一定要封装sdk。如果是服务端开发人员，如果多个项目都包含同一份sdk，一旦该sdk出了问题，就意味着所有相关项目都需要重新升级部署。这个时候就该考虑服务化了，如果该sdk相关逻辑在一个单独的服务里面，我们只需要更新该服务就行，这样相关项目与那段逻辑就实现了解耦。沈剑的这篇文章《小小的公共库，大大的耦合，你痛过吗？》，大家可以关注下。 本文链接：http://www.servercoder.com/2017/12/11/sdk-without-http/]]></content>
  </entry>
</search>
